{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import numpy as np\n",
    "import cvxpy as cp\n",
    "\n",
    "from cartpole.cartpole import Cartpole\n",
    "import pickle, os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#load train/test data\n",
    "prob = Cartpole() #use default config, pass different config file oth.\n",
    "config_fn = './cartpole/config/default.p'\n",
    "\n",
    "config_file = open(config_fn,'rb')\n",
    "dataset_name, _, _ = pickle.load(config_file); config_file.close()\n",
    "\n",
    "relative_path = os.getcwd()\n",
    "dataset_fn = relative_path + '/cartpole/data/' + dataset_name\n",
    "\n",
    "train_file = open(dataset_fn+'/train.p','rb')\n",
    "# p_train, x_train, u_train, y_train, c_train, times_train = pickle.load(train_file)\n",
    "train_data = pickle.load(train_file)\n",
    "train_file.close()\n",
    "\n",
    "test_file = open(dataset_fn+'/test.p','rb')\n",
    "# p_test, x_test, u_test, y_test, c_test, times_test = pickle.load(test_file)\n",
    "test_data = pickle.load(test_file)\n",
    "test_file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pre-processing\n",
    "\n",
    "#some function here to convert p_test into a feature matrix, X\n",
    "#some function here to convert y_test into strategy labels, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#training setup\n",
    "\n",
    "#instantiate Solver object\n",
    "#if first time, setup hyperparams + write out to a config file\n",
    "#else, load hyperparams from config (e.g. network weights, lr, etc.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#training step\n",
    "\n",
    "#either we can write a big loop here, or hide it in some Solver.train() method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#testing setp\n",
    "\n",
    "#either we can write a big loop here, or hide it in some Solver.test() method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## dummy cell to test basic Cartpole functionality\n",
    "\n",
    "xg = 0.1*np.random.randn(4); x0 = 0.1*np.random.randn(4) #dummy param values\n",
    "params = {'x0': x0,'xg' : xg} #put them into a dict\n",
    "strat = np.zeros((4,prob.N-1)).astype(int) #dummy strategy (all zeros)\n",
    "\n",
    "feas_bin, optval_bin, time_bin, assigns_bin = prob.solve_micp(params) #solve problem exactly\n",
    "feas, optval, time = prob.solve_pinned(params,strat)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# test MLOPT solver"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "589\n"
     ]
    }
   ],
   "source": [
    "from solvers.mlopt import MLOPT\n",
    "\n",
    "system = 'cartpole'\n",
    "prob_features = ['x0', 'xg']\n",
    "mlopt_obj = MLOPT(system, prob, prob_features)\n",
    "\n",
    "n_features = 8\n",
    "mlopt_obj.construct_strategies(n_features, train_data)\n",
    "print(mlopt_obj.n_strategies)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading presaved classifier model from mlopt_cartpole_20200622_1815.pt\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "FFNet(\n",
       "  (activation): ReLU()\n",
       "  (layers): ModuleList(\n",
       "    (0): Linear(in_features=8, out_features=32, bias=True)\n",
       "    (1): Linear(in_features=32, out_features=32, bias=True)\n",
       "    (2): Linear(in_features=32, out_features=32, bias=True)\n",
       "    (3): Linear(in_features=32, out_features=589, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mlopt_obj.setup_network()\n",
    "\n",
    "fn_saved = 'mlopt_cartpole_20200622_1815.pt'\n",
    "mlopt_obj.load_network(fn_saved)\n",
    "\n",
    "mlopt_obj.model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mlopt_obj.training_params['TRAINING_ITERATIONS'] = 1000\n",
    "mlopt_obj.train()\n",
    "print(mlopt_obj.model_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0\n"
     ]
    }
   ],
   "source": [
    "n_succ = 0\n",
    "count = 0\n",
    "\n",
    "for ii in range(1000):\n",
    "    prob_params = {}\n",
    "    idx = np.random.randint(test_data[1].shape[0])\n",
    "\n",
    "    p_test = test_data[0]\n",
    "    for k in p_test.keys():\n",
    "        prob_params[k] = p_test[k][idx]\n",
    "    prob_success, cost, total_time, n_evals = mlopt_obj.forward(prob_params)\n",
    "\n",
    "    count += 1\n",
    "    if prob_success:\n",
    "        n_succ += 1\n",
    "\n",
    "print(float(n_succ)/float(count))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'x0': array([ 0.46468615, -0.27337426, -0.85975189,  0.40075829]),\n",
       " 'xg': array([0., 0., 0., 0.])}"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prob_params = {}\n",
    "idx = np.random.randint(test_data[1].shape[0])\n",
    "\n",
    "p_test = test_data[0]\n",
    "for k in p_test.keys():\n",
    "    prob_params[k] = p_test[k][idx]\n",
    "prob_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "144.26570218216074\n"
     ]
    }
   ],
   "source": [
    "prob_success, cost, total_time, n_evals = mlopt_obj.forward(prob_params)\n",
    "\n",
    "if prob_success:\n",
    "    print(cost)\n",
    "else:\n",
    "    print('Failed')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Academic license - for non-commercial use only\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "144.2656965961387"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prob_success, true_cost, solve_time, optvals = mlopt_obj.problem.solve_micp(prob_params)\n",
    "\n",
    "true_cost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0\n"
     ]
    }
   ],
   "source": [
    "n_succ = 0\n",
    "count = 0\n",
    "\n",
    "for ii in range(100):\n",
    "    prob_params = {}\n",
    "    idx = np.random.randint(test_data[1].shape[0])\n",
    "\n",
    "    p_test = test_data[0]\n",
    "    for k in p_test.keys():\n",
    "        prob_params[k] = p_test[k][idx]\n",
    "    prob_success, cost, total_time, n_evals = mlopt_obj.forward(prob_params)\n",
    "\n",
    "    count += 1\n",
    "    if prob_success:\n",
    "        n_succ += 1\n",
    "\n",
    "print(float(n_succ)/float(count))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# test Regression solver"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from solvers.regression import Regression\n",
    "\n",
    "system = 'cartpole'\n",
    "prob_features = ['x0', 'xg']\n",
    "reg_obj = Regression(system, prob, prob_features)\n",
    "\n",
    "n_features = 8\n",
    "reg_obj.construct_strategies(n_features, train_data)\n",
    "print(reg_obj.n_strategies)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reg_obj.setup_network()\n",
    "reg_obj.model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reg_obj.training_params['TRAINING_ITERATIONS'] = 10\n",
    "reg_obj.training_params['CHECKPOINT_AFTER'] = 200000\n",
    "reg_obj.train()\n",
    "print(reg_obj.model_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prob_params = {}\n",
    "idx = 1\n",
    "\n",
    "p_test = train_data[0]\n",
    "for k in p_test.keys():\n",
    "    prob_params[k] = p_test[k][idx]\n",
    "prob_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prob_success, cost, total_time = reg_obj.forward(prob_params)\n",
    "\n",
    "if prob_success:\n",
    "    print(cost)\n",
    "else:\n",
    "    print('Failed')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mlopt",
   "language": "python",
   "name": "mlopt"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
