{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "import numpy as np\n",
    "import cvxpy as cp\n",
    "\n",
    "import torch\n",
    "from torch.autograd import Variable\n",
    "\n",
    "from free_flyer.free_flyer import FreeFlyer\n",
    "import pickle, os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#load train/test data\n",
    "prob = FreeFlyer() #use default config, pass different config file oth.\n",
    "config_fn = './free_flyer/config/default.p'\n",
    "\n",
    "config_file = open(config_fn,'rb')\n",
    "dataset_name, _, _ = pickle.load(config_file); config_file.close()\n",
    "\n",
    "relative_path = os.getcwd()\n",
    "dataset_fn = relative_path + '/free_flyer/data/' + dataset_name\n",
    "\n",
    "train_file = open(dataset_fn+'/train.p','rb')\n",
    "# p_train, x_train, u_train, y_train, c_train, times_train = pickle.load(train_file)\n",
    "train_data = pickle.load(train_file)\n",
    "train_file.close()\n",
    "\n",
    "test_file = open(dataset_fn+'/test.p','rb')\n",
    "# p_test, x_test, u_test, y_test, c_test, times_test = pickle.load(test_file)\n",
    "test_data = pickle.load(test_file)\n",
    "test_file.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# test task-specific MLOPT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from solvers.mlopt_ff import MLOPT_FF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "379\n"
     ]
    }
   ],
   "source": [
    "system = 'free_flyer'\n",
    "prob_features = ['x0', 'obstacles', 'obstacles_map']\n",
    "\n",
    "mlopt_ts_obj = MLOPT_FF(system, prob, prob_features)\n",
    "\n",
    "n_features = 36 + prob.n_obs\n",
    "mlopt_ts_obj.construct_strategies(n_features, train_data)\n",
    "print(mlopt_ts_obj.n_strategies)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pytorch.models.CNNet'>\n"
     ]
    }
   ],
   "source": [
    "mlopt_ts_obj.setup_network()\n",
    "\n",
    "# cnn_in = Variable(torch.from_numpy(mlopt_ts_obj.cnn_features[:2])).float()\n",
    "# ff_in = Variable(torch.from_numpy(mlopt_ts_obj.features[:2])).float()\n",
    "\n",
    "# mlopt_ts_obj.model(cnn_in, ff_in).detach().cpu().numpy()\n",
    "print(type(mlopt_ts_obj.model))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss:   3.172037363052368,   acc:  0.15625\n",
      "Done with epoch 0 in 5.178166627883911s\n",
      "loss:   2.665426015853882,   acc:  0.28125\n",
      "Done with epoch 1 in 4.988928318023682s\n",
      "loss:   2.4943110942840576,   acc:  0.28125\n",
      "loss:   2.5960640907287598,   acc:  0.25\n",
      "Done with epoch 2 in 5.0579986572265625s\n",
      "loss:   2.933814287185669,   acc:  0.28125\n",
      "Done with epoch 3 in 5.01059627532959s\n",
      "loss:   3.0009925365448,   acc:  0.09375\n",
      "loss:   3.0832772254943848,   acc:  0.375\n",
      "Done with epoch 4 in 5.040608644485474s\n",
      "loss:   3.2641663551330566,   acc:  0.125\n",
      "Done with epoch 5 in 5.076635360717773s\n",
      "loss:   3.254560708999634,   acc:  0.125\n",
      "Done with epoch 6 in 5.005603075027466s\n",
      "loss:   2.4300215244293213,   acc:  0.25\n",
      "loss:   2.8489205837249756,   acc:  0.40625\n",
      "Done with epoch 7 in 5.015244245529175s\n",
      "loss:   3.4127659797668457,   acc:  0.21875\n",
      "Done with epoch 8 in 4.964863300323486s\n",
      "loss:   2.597259998321533,   acc:  0.21875\n",
      "loss:   2.5296313762664795,   acc:  0.3125\n",
      "Done with epoch 9 in 5.040590524673462s\n",
      "loss:   2.9859046936035156,   acc:  0.15625\n",
      "Done with epoch 10 in 5.010607481002808s\n",
      "loss:   3.0368311405181885,   acc:  0.15625\n",
      "Done with epoch 11 in 5.054202079772949s\n",
      "loss:   2.647486448287964,   acc:  0.15625\n",
      "loss:   2.7450907230377197,   acc:  0.1875\n",
      "Done with epoch 12 in 5.047719955444336s\n",
      "loss:   2.5262837409973145,   acc:  0.21875\n",
      "Done with epoch 13 in 4.998533487319946s\n",
      "loss:   2.665695905685425,   acc:  0.34375\n",
      "loss:   2.7857820987701416,   acc:  0.25\n",
      "Done with epoch 14 in 4.981677293777466s\n",
      "loss:   2.888064384460449,   acc:  0.28125\n",
      "Done with epoch 15 in 4.963006496429443s\n",
      "loss:   2.1190154552459717,   acc:  0.40625\n",
      "Done with epoch 16 in 5.0448057651519775s\n",
      "loss:   2.4742534160614014,   acc:  0.3125\n",
      "loss:   2.307548999786377,   acc:  0.40625\n",
      "Done with epoch 17 in 5.093784332275391s\n",
      "loss:   2.585543155670166,   acc:  0.25\n",
      "Done with epoch 18 in 4.9728827476501465s\n",
      "loss:   2.973499059677124,   acc:  0.28125\n",
      "loss:   3.0496115684509277,   acc:  0.3125\n",
      "Done with epoch 19 in 5.06154203414917s\n",
      "loss:   3.170259475708008,   acc:  0.25\n",
      "Done with epoch 20 in 5.101912260055542s\n",
      "loss:   3.0477192401885986,   acc:  0.3125\n",
      "Saved model at /home/acauligi/cs_234/project/mlopt-micp/mlopt_free_flyer_20200629_1010.pt\n",
      "Done with epoch 21 in 4.949875831604004s\n",
      "loss:   2.6809709072113037,   acc:  0.28125\n",
      "loss:   2.467869281768799,   acc:  0.3125\n",
      "Done with epoch 22 in 5.107110023498535s\n",
      "loss:   2.9059417247772217,   acc:  0.28125\n",
      "Done with epoch 23 in 5.009250164031982s\n",
      "loss:   2.707592725753784,   acc:  0.28125\n",
      "loss:   3.1843652725219727,   acc:  0.3125\n",
      "Done with epoch 24 in 5.045697450637817s\n",
      "loss:   2.6779446601867676,   acc:  0.21875\n",
      "Done with epoch 25 in 5.010347366333008s\n",
      "loss:   2.6162755489349365,   acc:  0.34375\n",
      "Done with epoch 26 in 5.166851758956909s\n",
      "loss:   2.719869613647461,   acc:  0.1875\n",
      "loss:   2.5096051692962646,   acc:  0.25\n",
      "Done with epoch 27 in 5.200299024581909s\n",
      "loss:   2.711104393005371,   acc:  0.3125\n",
      "Done with epoch 28 in 5.08894944190979s\n",
      "loss:   2.1157052516937256,   acc:  0.375\n",
      "loss:   2.4995462894439697,   acc:  0.1875\n",
      "Done with epoch 29 in 5.170678615570068s\n",
      "loss:   3.0509023666381836,   acc:  0.09375\n",
      "Done with epoch 30 in 5.008798122406006s\n",
      "loss:   3.103142023086548,   acc:  0.21875\n",
      "loss:   3.102924346923828,   acc:  0.21875\n",
      "Done with epoch 31 in 4.983159780502319s\n",
      "loss:   3.42952561378479,   acc:  0.15625\n",
      "Done with epoch 32 in 5.139086723327637s\n",
      "loss:   2.904205560684204,   acc:  0.25\n",
      "Done with epoch 33 in 4.964983701705933s\n",
      "loss:   2.4848527908325195,   acc:  0.25\n",
      "loss:   3.0974795818328857,   acc:  0.21875\n",
      "Done with epoch 34 in 5.079359292984009s\n",
      "loss:   2.5676109790802,   acc:  0.375\n",
      "Done with epoch 35 in 5.261865615844727s\n",
      "loss:   2.3651371002197266,   acc:  0.28125\n",
      "loss:   3.3082547187805176,   acc:  0.09375\n",
      "Done with epoch 36 in 5.141265153884888s\n",
      "loss:   2.5616579055786133,   acc:  0.28125\n",
      "Done with epoch 37 in 4.968474388122559s\n",
      "loss:   2.704415798187256,   acc:  0.34375\n",
      "Done with epoch 38 in 4.951211214065552s\n",
      "loss:   2.6033918857574463,   acc:  0.28125\n",
      "loss:   2.97749662399292,   acc:  0.125\n",
      "Done with epoch 39 in 5.1753764152526855s\n",
      "loss:   3.249692440032959,   acc:  0.125\n",
      "Done with epoch 40 in 5.140127420425415s\n",
      "loss:   2.75592303276062,   acc:  0.40625\n",
      "loss:   2.7526071071624756,   acc:  0.15625\n",
      "Done with epoch 41 in 5.317283630371094s\n",
      "loss:   2.5769598484039307,   acc:  0.3125\n",
      "Saved model at /home/acauligi/cs_234/project/mlopt-micp/mlopt_free_flyer_20200629_1010.pt\n",
      "Done with epoch 42 in 5.008738040924072s\n",
      "loss:   2.9063334465026855,   acc:  0.28125\n",
      "Done with epoch 43 in 5.171366214752197s\n",
      "loss:   2.9180381298065186,   acc:  0.3125\n",
      "loss:   2.4442477226257324,   acc:  0.3125\n",
      "Done with epoch 44 in 5.188538312911987s\n",
      "loss:   2.578620433807373,   acc:  0.25\n",
      "Done with epoch 45 in 5.11217999458313s\n",
      "loss:   3.0240797996520996,   acc:  0.15625\n",
      "loss:   3.0800135135650635,   acc:  0.25\n",
      "Done with epoch 46 in 5.153439283370972s\n",
      "loss:   2.798067569732666,   acc:  0.1875\n",
      "Done with epoch 47 in 5.079046249389648s\n",
      "loss:   2.8095102310180664,   acc:  0.3125\n",
      "Done with epoch 48 in 5.032680988311768s\n",
      "loss:   2.1561026573181152,   acc:  0.375\n",
      "loss:   2.609349012374878,   acc:  0.25\n",
      "Done with epoch 49 in 5.091667890548706s\n",
      "loss:   2.8218846321105957,   acc:  0.28125\n",
      "Done with epoch 50 in 5.468427658081055s\n",
      "loss:   2.3700802326202393,   acc:  0.3125\n",
      "loss:   2.5291428565979004,   acc:  0.25\n",
      "Done with epoch 51 in 5.258827447891235s\n",
      "loss:   2.9103915691375732,   acc:  0.21875\n",
      "Done with epoch 52 in 5.124007225036621s\n",
      "loss:   2.48537540435791,   acc:  0.28125\n",
      "Done with epoch 53 in 5.0594775676727295s\n",
      "loss:   2.5899274349212646,   acc:  0.375\n",
      "loss:   2.7284107208251953,   acc:  0.28125\n",
      "Done with epoch 54 in 5.284532785415649s\n",
      "loss:   2.8574252128601074,   acc:  0.3125\n",
      "Done with epoch 55 in 5.125210762023926s\n",
      "loss:   2.2928969860076904,   acc:  0.28125\n",
      "loss:   2.9485971927642822,   acc:  0.15625\n",
      "Done with epoch 56 in 5.161893606185913s\n",
      "loss:   2.9244651794433594,   acc:  0.28125\n",
      "Done with epoch 57 in 5.063738822937012s\n",
      "loss:   2.628185510635376,   acc:  0.1875\n",
      "loss:   3.026142120361328,   acc:  0.1875\n",
      "Done with epoch 58 in 5.019501209259033s\n",
      "loss:   2.562567710876465,   acc:  0.15625\n",
      "Done with epoch 59 in 5.233055591583252s\n",
      "loss:   3.0630781650543213,   acc:  0.21875\n",
      "Done with epoch 60 in 5.124517917633057s\n",
      "loss:   2.2715847492218018,   acc:  0.34375\n",
      "loss:   2.9292490482330322,   acc:  0.21875\n",
      "Done with epoch 61 in 5.232497930526733s\n",
      "loss:   2.705684185028076,   acc:  0.21875\n",
      "Done with epoch 62 in 5.115556240081787s\n",
      "loss:   2.672819137573242,   acc:  0.34375\n",
      "loss:   2.7710089683532715,   acc:  0.3125\n",
      "Saved model at /home/acauligi/cs_234/project/mlopt-micp/mlopt_free_flyer_20200629_1010.pt\n",
      "Done with epoch 63 in 5.168051481246948s\n",
      "loss:   2.5688090324401855,   acc:  0.3125\n",
      "Done with epoch 64 in 5.147244691848755s\n",
      "loss:   2.563678026199341,   acc:  0.25\n",
      "Done with epoch 65 in 5.219738960266113s\n",
      "loss:   2.5037472248077393,   acc:  0.28125\n",
      "loss:   2.8348872661590576,   acc:  0.34375\n",
      "Done with epoch 66 in 5.417926073074341s\n",
      "loss:   2.79146409034729,   acc:  0.3125\n",
      "Done with epoch 67 in 5.167966842651367s\n",
      "loss:   3.0954980850219727,   acc:  0.28125\n",
      "loss:   2.3426268100738525,   acc:  0.34375\n",
      "Done with epoch 68 in 4.989440679550171s\n",
      "loss:   2.731318235397339,   acc:  0.21875\n",
      "Done with epoch 69 in 5.0195631980896s\n",
      "loss:   2.773061752319336,   acc:  0.28125\n",
      "Done with epoch 70 in 5.015085458755493s\n",
      "loss:   3.5052201747894287,   acc:  0.1875\n",
      "loss:   2.4444546699523926,   acc:  0.28125\n",
      "Done with epoch 71 in 5.138031482696533s\n",
      "loss:   2.651834487915039,   acc:  0.28125\n",
      "Done with epoch 72 in 5.106529474258423s\n",
      "loss:   2.6389756202697754,   acc:  0.25\n",
      "loss:   2.589911937713623,   acc:  0.15625\n",
      "Done with epoch 73 in 5.155807971954346s\n",
      "loss:   2.7357912063598633,   acc:  0.21875\n",
      "Done with epoch 74 in 5.660414218902588s\n",
      "loss:   2.8068788051605225,   acc:  0.25\n",
      "Done with epoch 75 in 5.4127562046051025s\n",
      "loss:   2.9909133911132812,   acc:  0.21875\n",
      "loss:   3.055938243865967,   acc:  0.25\n",
      "Done with epoch 76 in 5.232063293457031s\n",
      "loss:   2.3805603981018066,   acc:  0.25\n",
      "Done with epoch 77 in 5.043371677398682s\n",
      "loss:   2.3931703567504883,   acc:  0.3125\n",
      "loss:   2.5094504356384277,   acc:  0.34375\n",
      "Done with epoch 78 in 4.98878288269043s\n",
      "loss:   2.627387762069702,   acc:  0.3125\n",
      "Done with epoch 79 in 4.979377508163452s\n",
      "loss:   2.9307432174682617,   acc:  0.25\n",
      "Done with epoch 80 in 5.063763856887817s\n",
      "loss:   2.1895456314086914,   acc:  0.28125\n",
      "loss:   2.6107349395751953,   acc:  0.28125\n",
      "Done with epoch 81 in 5.069319486618042s\n",
      "loss:   2.8531277179718018,   acc:  0.1875\n",
      "Done with epoch 82 in 5.058398962020874s\n",
      "loss:   3.548098564147949,   acc:  0.1875\n",
      "loss:   2.6359331607818604,   acc:  0.21875\n",
      "Done with epoch 83 in 5.025092601776123s\n",
      "loss:   2.889467477798462,   acc:  0.375\n",
      "Done with epoch 84 in 4.965689420700073s\n",
      "loss:   2.913839817047119,   acc:  0.25\n",
      "Saved model at /home/acauligi/cs_234/project/mlopt-micp/mlopt_free_flyer_20200629_1010.pt\n",
      "loss:   2.537670850753784,   acc:  0.28125\n",
      "Done with epoch 85 in 5.015382766723633s\n",
      "loss:   2.7668166160583496,   acc:  0.21875\n",
      "Done with epoch 86 in 4.968783617019653s\n",
      "loss:   2.824281692504883,   acc:  0.09375\n",
      "Done with epoch 87 in 4.97248911857605s\n",
      "loss:   2.792924404144287,   acc:  0.25\n",
      "loss:   2.7523393630981445,   acc:  0.1875\n",
      "Done with epoch 88 in 4.985440015792847s\n",
      "loss:   2.819195508956909,   acc:  0.25\n",
      "Done with epoch 89 in 5.02978777885437s\n",
      "loss:   2.926445722579956,   acc:  0.3125\n",
      "loss:   2.841421604156494,   acc:  0.34375\n",
      "Done with epoch 90 in 5.047395467758179s\n",
      "loss:   3.1608798503875732,   acc:  0.3125\n",
      "Done with epoch 91 in 5.047420978546143s\n",
      "loss:   3.3375754356384277,   acc:  0.3125\n",
      "Done with epoch 92 in 4.980901002883911s\n",
      "loss:   2.6919994354248047,   acc:  0.28125\n",
      "loss:   2.5964062213897705,   acc:  0.1875\n",
      "Done with epoch 93 in 4.982449531555176s\n",
      "loss:   2.678858757019043,   acc:  0.21875\n",
      "Done with epoch 94 in 4.958773136138916s\n",
      "loss:   2.892066717147827,   acc:  0.1875\n",
      "loss:   3.1434707641601562,   acc:  0.1875\n",
      "Done with epoch 95 in 5.071033954620361s\n",
      "loss:   3.5116703510284424,   acc:  0.125\n",
      "Done with epoch 96 in 4.981907844543457s\n",
      "loss:   2.516659736633301,   acc:  0.125\n",
      "Done with epoch 97 in 4.95773720741272s\n",
      "loss:   2.3977091312408447,   acc:  0.15625\n",
      "loss:   2.436069965362549,   acc:  0.25\n",
      "Done with epoch 98 in 5.129075288772583s\n",
      "loss:   2.970484733581543,   acc:  0.15625\n",
      "Done with epoch 99 in 4.980426788330078s\n",
      "loss:   2.7944583892822266,   acc:  0.25\n",
      "loss:   2.9970078468322754,   acc:  0.25\n",
      "Done with epoch 100 in 5.095739364624023s\n",
      "loss:   2.7612056732177734,   acc:  0.125\n",
      "Done with epoch 101 in 4.990655899047852s\n",
      "loss:   2.8641371726989746,   acc:  0.40625\n",
      "Done with epoch 102 in 5.194979190826416s\n",
      "loss:   2.67681884765625,   acc:  0.4375\n",
      "loss:   2.592660665512085,   acc:  0.21875\n",
      "Done with epoch 103 in 5.067218780517578s\n",
      "loss:   2.4291458129882812,   acc:  0.25\n",
      "Done with epoch 104 in 5.134958982467651s\n",
      "loss:   2.7191131114959717,   acc:  0.1875\n",
      "loss:   2.6049132347106934,   acc:  0.21875\n",
      "Done with epoch 105 in 5.09624981880188s\n",
      "loss:   2.3410558700561523,   acc:  0.28125\n",
      "Saved model at /home/acauligi/cs_234/project/mlopt-micp/mlopt_free_flyer_20200629_1010.pt\n",
      "Done with epoch 106 in 5.193914413452148s\n",
      "loss:   2.548696517944336,   acc:  0.21875\n",
      "Done with epoch 107 in 4.9673380851745605s\n",
      "loss:   2.8300628662109375,   acc:  0.28125\n",
      "loss:   3.2970080375671387,   acc:  0.21875\n",
      "Done with epoch 108 in 4.9731011390686035s\n",
      "loss:   2.5739495754241943,   acc:  0.25\n",
      "Done with epoch 109 in 4.993645906448364s\n",
      "loss:   2.778627395629883,   acc:  0.28125\n",
      "loss:   3.0451431274414062,   acc:  0.25\n",
      "Done with epoch 110 in 4.968701124191284s\n",
      "loss:   3.3073198795318604,   acc:  0.25\n",
      "Done with epoch 111 in 5.026791334152222s\n",
      "loss:   2.9378302097320557,   acc:  0.25\n",
      "Done with epoch 112 in 4.963084936141968s\n",
      "loss:   2.237401247024536,   acc:  0.375\n",
      "loss:   3.083576202392578,   acc:  0.21875\n",
      "Done with epoch 113 in 5.118252277374268s\n",
      "loss:   2.6573379039764404,   acc:  0.3125\n",
      "Done with epoch 114 in 4.983426570892334s\n",
      "loss:   2.86055064201355,   acc:  0.1875\n",
      "loss:   2.692528486251831,   acc:  0.25\n",
      "Done with epoch 115 in 5.156671524047852s\n",
      "loss:   3.113577365875244,   acc:  0.15625\n",
      "Done with epoch 116 in 5.003306150436401s\n",
      "loss:   3.0190813541412354,   acc:  0.1875\n",
      "loss:   2.97756028175354,   acc:  0.21875\n",
      "Done with epoch 117 in 4.930382013320923s\n",
      "loss:   2.6734580993652344,   acc:  0.1875\n",
      "Done with epoch 118 in 5.12243914604187s\n",
      "loss:   3.159468412399292,   acc:  0.0625\n",
      "Done with epoch 119 in 5.101135730743408s\n",
      "loss:   3.126276731491089,   acc:  0.125\n",
      "loss:   2.6432342529296875,   acc:  0.1875\n",
      "Done with epoch 120 in 5.159088373184204s\n",
      "loss:   3.5924932956695557,   acc:  0.21875\n",
      "Done with epoch 121 in 5.001552104949951s\n",
      "loss:   2.644291877746582,   acc:  0.21875\n",
      "loss:   3.0032496452331543,   acc:  0.1875\n",
      "Done with epoch 122 in 5.007347345352173s\n",
      "loss:   2.968339443206787,   acc:  0.25\n",
      "Done with epoch 123 in 5.157808065414429s\n",
      "loss:   2.4865658283233643,   acc:  0.25\n",
      "Done with epoch 124 in 4.984631299972534s\n",
      "loss:   2.7481560707092285,   acc:  0.3125\n",
      "loss:   2.9026389122009277,   acc:  0.1875\n",
      "Done with epoch 125 in 5.204032897949219s\n",
      "loss:   2.729153871536255,   acc:  0.25\n",
      "Done with epoch 126 in 5.03111457824707s\n",
      "loss:   2.410767078399658,   acc:  0.3125\n",
      "loss:   2.7379093170166016,   acc:  0.28125\n",
      "Saved model at /home/acauligi/cs_234/project/mlopt-micp/mlopt_free_flyer_20200629_1010.pt\n",
      "Done with epoch 127 in 5.072803497314453s\n",
      "loss:   2.9020514488220215,   acc:  0.15625\n",
      "Done with epoch 128 in 5.022527694702148s\n",
      "loss:   2.746192216873169,   acc:  0.21875\n",
      "Done with epoch 129 in 4.928457021713257s\n",
      "loss:   3.0278494358062744,   acc:  0.125\n",
      "loss:   3.179880142211914,   acc:  0.25\n",
      "Done with epoch 130 in 5.164395570755005s\n",
      "loss:   2.773784637451172,   acc:  0.25\n",
      "Done with epoch 131 in 4.93053126335144s\n",
      "loss:   2.4234554767608643,   acc:  0.25\n",
      "loss:   2.3987574577331543,   acc:  0.375\n",
      "Done with epoch 132 in 5.051332235336304s\n",
      "loss:   2.711890459060669,   acc:  0.125\n",
      "Done with epoch 133 in 5.000257730484009s\n",
      "loss:   2.9824399948120117,   acc:  0.1875\n",
      "Done with epoch 134 in 5.075168132781982s\n",
      "loss:   3.060232162475586,   acc:  0.21875\n",
      "loss:   2.9364326000213623,   acc:  0.375\n",
      "Done with epoch 135 in 5.185158014297485s\n",
      "loss:   2.6224141120910645,   acc:  0.1875\n",
      "Done with epoch 136 in 4.977882385253906s\n",
      "loss:   2.5881292819976807,   acc:  0.25\n",
      "loss:   2.8044443130493164,   acc:  0.25\n",
      "Done with epoch 137 in 5.087029933929443s\n",
      "loss:   2.5721471309661865,   acc:  0.34375\n",
      "Done with epoch 138 in 4.986660957336426s\n",
      "loss:   2.6712474822998047,   acc:  0.25\n",
      "Done with epoch 139 in 4.948976755142212s\n",
      "loss:   2.8022067546844482,   acc:  0.28125\n",
      "loss:   2.940338134765625,   acc:  0.28125\n",
      "Done with epoch 140 in 5.142792701721191s\n",
      "loss:   3.033836603164673,   acc:  0.25\n",
      "Done with epoch 141 in 4.982857942581177s\n",
      "loss:   2.6776366233825684,   acc:  0.28125\n",
      "loss:   2.889240264892578,   acc:  0.21875\n",
      "Done with epoch 142 in 5.0369648933410645s\n",
      "loss:   2.5997750759124756,   acc:  0.21875\n",
      "Done with epoch 143 in 5.15231990814209s\n",
      "loss:   2.9184978008270264,   acc:  0.34375\n",
      "loss:   2.878925085067749,   acc:  0.34375\n",
      "Done with epoch 144 in 5.125186443328857s\n",
      "loss:   3.057638645172119,   acc:  0.25\n",
      "Done with epoch 145 in 5.0716023445129395s\n",
      "loss:   3.3388986587524414,   acc:  0.1875\n",
      "Done with epoch 146 in 5.131290435791016s\n",
      "loss:   2.1012778282165527,   acc:  0.25\n",
      "loss:   2.4280643463134766,   acc:  0.375\n",
      "Done with epoch 147 in 5.160264730453491s\n",
      "loss:   3.094153881072998,   acc:  0.1875\n",
      "Done with epoch 148 in 5.141400337219238s\n",
      "loss:   3.063464641571045,   acc:  0.21875\n",
      "Saved model at /home/acauligi/cs_234/project/mlopt-micp/mlopt_free_flyer_20200629_1010.pt\n",
      "loss:   2.1816444396972656,   acc:  0.40625\n",
      "Done with epoch 149 in 5.168067455291748s\n",
      "loss:   2.6364645957946777,   acc:  0.28125\n",
      "Done with epoch 150 in 5.145151138305664s\n",
      "loss:   3.009078025817871,   acc:  0.28125\n",
      "Done with epoch 151 in 5.116833925247192s\n",
      "loss:   2.7838878631591797,   acc:  0.1875\n",
      "loss:   2.8631374835968018,   acc:  0.21875\n",
      "Done with epoch 152 in 5.013574123382568s\n",
      "loss:   2.462449789047241,   acc:  0.375\n",
      "Done with epoch 153 in 4.927985429763794s\n",
      "loss:   3.072803020477295,   acc:  0.21875\n",
      "loss:   2.901729106903076,   acc:  0.0625\n",
      "Done with epoch 154 in 5.0072550773620605s\n",
      "loss:   3.1527743339538574,   acc:  0.15625\n",
      "Done with epoch 155 in 4.971802473068237s\n",
      "loss:   2.266521692276001,   acc:  0.4375\n",
      "Done with epoch 156 in 4.994019269943237s\n",
      "loss:   2.811159372329712,   acc:  0.28125\n",
      "loss:   2.50565242767334,   acc:  0.3125\n",
      "Done with epoch 157 in 4.9518187046051025s\n",
      "loss:   2.7231523990631104,   acc:  0.28125\n",
      "Done with epoch 158 in 4.875572204589844s\n",
      "loss:   2.677903652191162,   acc:  0.21875\n",
      "loss:   2.600403308868408,   acc:  0.3125\n",
      "Done with epoch 159 in 4.999791145324707s\n",
      "loss:   2.8133955001831055,   acc:  0.34375\n",
      "Done with epoch 160 in 4.9758477210998535s\n",
      "loss:   3.258111000061035,   acc:  0.15625\n",
      "Done with epoch 161 in 5.130622386932373s\n",
      "loss:   3.3316140174865723,   acc:  0.125\n",
      "loss:   3.1413733959198,   acc:  0.15625\n",
      "Done with epoch 162 in 5.13524055480957s\n",
      "loss:   2.5497546195983887,   acc:  0.15625\n",
      "Done with epoch 163 in 5.076641082763672s\n",
      "loss:   2.4484658241271973,   acc:  0.25\n",
      "loss:   2.7652883529663086,   acc:  0.25\n",
      "Done with epoch 164 in 5.242848634719849s\n",
      "loss:   2.4418344497680664,   acc:  0.21875\n",
      "Done with epoch 165 in 5.074265480041504s\n",
      "loss:   2.802764892578125,   acc:  0.28125\n",
      "Done with epoch 166 in 4.955898761749268s\n",
      "loss:   3.1227259635925293,   acc:  0.21875\n",
      "loss:   3.4311344623565674,   acc:  0.25\n",
      "Done with epoch 167 in 4.988694906234741s\n",
      "loss:   2.55491042137146,   acc:  0.28125\n",
      "Done with epoch 168 in 4.974629640579224s\n",
      "loss:   2.712981700897217,   acc:  0.3125\n",
      "loss:   2.385192632675171,   acc:  0.25\n",
      "Done with epoch 169 in 5.057126760482788s\n",
      "loss:   3.0021886825561523,   acc:  0.21875\n",
      "Saved model at /home/acauligi/cs_234/project/mlopt-micp/mlopt_free_flyer_20200629_1010.pt\n",
      "Done with epoch 170 in 5.1172707080841064s\n",
      "loss:   2.7775533199310303,   acc:  0.3125\n",
      "loss:   2.4099128246307373,   acc:  0.28125\n",
      "Done with epoch 171 in 5.190956354141235s\n",
      "loss:   2.466463565826416,   acc:  0.375\n",
      "Done with epoch 172 in 5.056790590286255s\n",
      "loss:   2.4504916667938232,   acc:  0.15625\n",
      "Done with epoch 173 in 5.092014312744141s\n",
      "loss:   3.2413032054901123,   acc:  0.3125\n",
      "loss:   2.7309517860412598,   acc:  0.3125\n",
      "Done with epoch 174 in 5.174562454223633s\n",
      "loss:   3.1170570850372314,   acc:  0.15625\n",
      "Done with epoch 175 in 5.052334547042847s\n",
      "loss:   2.730534791946411,   acc:  0.28125\n",
      "loss:   3.0021812915802,   acc:  0.21875\n",
      "Done with epoch 176 in 5.0185158252716064s\n",
      "loss:   2.7361838817596436,   acc:  0.1875\n",
      "Done with epoch 177 in 4.942788362503052s\n",
      "loss:   3.1290907859802246,   acc:  0.25\n",
      "Done with epoch 178 in 5.05484938621521s\n",
      "loss:   2.462705612182617,   acc:  0.3125\n",
      "loss:   3.4512648582458496,   acc:  0.09375\n",
      "Done with epoch 179 in 5.00879430770874s\n",
      "loss:   2.5842554569244385,   acc:  0.21875\n",
      "Done with epoch 180 in 5.125240802764893s\n",
      "loss:   2.4389586448669434,   acc:  0.3125\n",
      "loss:   2.5477960109710693,   acc:  0.21875\n",
      "Done with epoch 181 in 5.1529130935668945s\n",
      "loss:   3.0721609592437744,   acc:  0.34375\n",
      "Done with epoch 182 in 5.0997350215911865s\n",
      "loss:   2.2577223777770996,   acc:  0.3125\n",
      "Done with epoch 183 in 4.924949884414673s\n",
      "loss:   2.7904226779937744,   acc:  0.1875\n",
      "loss:   3.2276947498321533,   acc:  0.28125\n",
      "Done with epoch 184 in 5.051229000091553s\n",
      "loss:   3.039255142211914,   acc:  0.28125\n",
      "Done with epoch 185 in 4.996455669403076s\n",
      "loss:   3.4405934810638428,   acc:  0.15625\n",
      "loss:   2.5575623512268066,   acc:  0.34375\n",
      "Done with epoch 186 in 5.07044792175293s\n",
      "loss:   2.87888503074646,   acc:  0.21875\n",
      "Done with epoch 187 in 5.099769592285156s\n",
      "loss:   3.05361270904541,   acc:  0.25\n",
      "Done with epoch 188 in 4.998250722885132s\n",
      "loss:   2.6830954551696777,   acc:  0.1875\n",
      "loss:   3.0157856941223145,   acc:  0.1875\n",
      "Done with epoch 189 in 5.1874871253967285s\n",
      "loss:   2.6873672008514404,   acc:  0.21875\n",
      "Done with epoch 190 in 5.111329078674316s\n",
      "loss:   2.5079078674316406,   acc:  0.15625\n",
      "loss:   3.293428421020508,   acc:  0.25\n",
      "Saved model at /home/acauligi/cs_234/project/mlopt-micp/mlopt_free_flyer_20200629_1010.pt\n",
      "Done with epoch 191 in 5.195597887039185s\n",
      "loss:   2.898427963256836,   acc:  0.21875\n",
      "Done with epoch 192 in 5.153617858886719s\n",
      "loss:   2.5903916358947754,   acc:  0.1875\n",
      "Done with epoch 193 in 5.134430408477783s\n",
      "loss:   2.6602988243103027,   acc:  0.3125\n",
      "loss:   2.4570960998535156,   acc:  0.34375\n",
      "Done with epoch 194 in 5.094567775726318s\n",
      "loss:   2.8655223846435547,   acc:  0.125\n",
      "Done with epoch 195 in 5.097119331359863s\n",
      "loss:   2.5731823444366455,   acc:  0.25\n",
      "loss:   2.618495464324951,   acc:  0.3125\n",
      "Done with epoch 196 in 5.305726051330566s\n",
      "loss:   2.5121190547943115,   acc:  0.3125\n",
      "Done with epoch 197 in 5.025845050811768s\n",
      "loss:   2.6930360794067383,   acc:  0.21875\n",
      "Done with epoch 198 in 5.1381494998931885s\n",
      "loss:   2.488867998123169,   acc:  0.21875\n",
      "loss:   2.521733522415161,   acc:  0.34375\n",
      "Done with epoch 199 in 5.23943829536438s\n",
      "loss:   3.03962779045105,   acc:  0.1875\n",
      "Done with epoch 200 in 5.054020404815674s\n",
      "loss:   2.7868974208831787,   acc:  0.15625\n",
      "loss:   2.735793113708496,   acc:  0.25\n",
      "Done with epoch 201 in 5.184953451156616s\n",
      "loss:   2.713144540786743,   acc:  0.1875\n",
      "Done with epoch 202 in 5.256807804107666s\n",
      "loss:   3.240879774093628,   acc:  0.1875\n",
      "loss:   3.2495105266571045,   acc:  0.09375\n",
      "Done with epoch 203 in 5.155616283416748s\n",
      "loss:   3.0287249088287354,   acc:  0.21875\n",
      "Done with epoch 204 in 5.174506187438965s\n",
      "loss:   3.1598076820373535,   acc:  0.15625\n",
      "Done with epoch 205 in 5.088063955307007s\n",
      "loss:   2.7040727138519287,   acc:  0.25\n",
      "loss:   3.216179847717285,   acc:  0.1875\n",
      "Done with epoch 206 in 4.988795280456543s\n",
      "loss:   2.652576208114624,   acc:  0.1875\n",
      "Done with epoch 207 in 4.952866077423096s\n",
      "loss:   2.5303361415863037,   acc:  0.34375\n",
      "loss:   2.6454243659973145,   acc:  0.15625\n",
      "Done with epoch 208 in 4.953430414199829s\n",
      "loss:   2.9396486282348633,   acc:  0.1875\n",
      "Done with epoch 209 in 5.14265251159668s\n",
      "loss:   2.9490020275115967,   acc:  0.125\n",
      "Done with epoch 210 in 5.11689305305481s\n",
      "loss:   2.630164384841919,   acc:  0.1875\n",
      "loss:   3.1307499408721924,   acc:  0.1875\n",
      "Done with epoch 211 in 5.13109827041626s\n",
      "loss:   3.0944783687591553,   acc:  0.125\n",
      "Done with epoch 212 in 5.14473032951355s\n",
      "loss:   2.2514259815216064,   acc:  0.375\n",
      "Saved model at /home/acauligi/cs_234/project/mlopt-micp/mlopt_free_flyer_20200629_1010.pt\n",
      "loss:   2.6029763221740723,   acc:  0.21875\n",
      "Done with epoch 213 in 5.105844259262085s\n",
      "loss:   2.545060157775879,   acc:  0.3125\n",
      "Done with epoch 214 in 5.125620603561401s\n",
      "loss:   2.6935086250305176,   acc:  0.21875\n",
      "Done with epoch 215 in 4.987666130065918s\n",
      "loss:   3.09657621383667,   acc:  0.15625\n",
      "loss:   2.6037838459014893,   acc:  0.21875\n",
      "Done with epoch 216 in 5.088458061218262s\n",
      "loss:   2.6895534992218018,   acc:  0.1875\n",
      "Done with epoch 217 in 5.08988618850708s\n",
      "loss:   3.0161688327789307,   acc:  0.34375\n",
      "loss:   2.588702917098999,   acc:  0.28125\n",
      "Done with epoch 218 in 5.0896360874176025s\n",
      "loss:   3.0272061824798584,   acc:  0.21875\n",
      "Done with epoch 219 in 5.0313732624053955s\n",
      "loss:   2.5028345584869385,   acc:  0.28125\n",
      "Done with epoch 220 in 4.9955058097839355s\n",
      "loss:   2.489640235900879,   acc:  0.34375\n",
      "loss:   2.662076473236084,   acc:  0.21875\n",
      "Done with epoch 221 in 5.016773700714111s\n",
      "loss:   2.851698398590088,   acc:  0.21875\n",
      "Done with epoch 222 in 5.025542259216309s\n",
      "loss:   2.677769660949707,   acc:  0.25\n",
      "loss:   2.7740323543548584,   acc:  0.28125\n",
      "Done with epoch 223 in 5.164786338806152s\n",
      "loss:   2.588665723800659,   acc:  0.34375\n",
      "Done with epoch 224 in 5.020708799362183s\n",
      "loss:   2.9078550338745117,   acc:  0.375\n",
      "Done with epoch 225 in 5.091718912124634s\n",
      "loss:   3.0623157024383545,   acc:  0.21875\n",
      "loss:   2.9204142093658447,   acc:  0.1875\n",
      "Done with epoch 226 in 5.002598285675049s\n",
      "loss:   2.4743165969848633,   acc:  0.1875\n",
      "Done with epoch 227 in 5.091646194458008s\n",
      "loss:   2.683738946914673,   acc:  0.3125\n",
      "loss:   2.7297661304473877,   acc:  0.28125\n",
      "Done with epoch 228 in 5.221980810165405s\n",
      "loss:   2.705874443054199,   acc:  0.125\n",
      "Done with epoch 229 in 5.161139965057373s\n",
      "loss:   2.8751606941223145,   acc:  0.25\n",
      "loss:   2.6285641193389893,   acc:  0.34375\n",
      "Done with epoch 230 in 5.100608587265015s\n",
      "loss:   2.914569616317749,   acc:  0.25\n",
      "Done with epoch 231 in 4.985710859298706s\n",
      "loss:   2.6310160160064697,   acc:  0.25\n",
      "Done with epoch 232 in 5.067968845367432s\n",
      "loss:   2.7032268047332764,   acc:  0.21875\n",
      "loss:   3.0160441398620605,   acc:  0.28125\n",
      "Done with epoch 233 in 5.238306522369385s\n",
      "loss:   2.0622053146362305,   acc:  0.34375\n",
      "Saved model at /home/acauligi/cs_234/project/mlopt-micp/mlopt_free_flyer_20200629_1010.pt\n",
      "Done with epoch 234 in 5.110004663467407s\n",
      "loss:   2.7666187286376953,   acc:  0.1875\n",
      "loss:   2.985809803009033,   acc:  0.34375\n",
      "Done with epoch 235 in 5.157922267913818s\n",
      "loss:   2.4018537998199463,   acc:  0.28125\n",
      "Done with epoch 236 in 5.068485498428345s\n",
      "loss:   2.889075756072998,   acc:  0.28125\n",
      "Done with epoch 237 in 5.095545053482056s\n",
      "loss:   2.785184860229492,   acc:  0.21875\n",
      "loss:   2.562023401260376,   acc:  0.28125\n",
      "Done with epoch 238 in 5.179210424423218s\n",
      "loss:   2.96513295173645,   acc:  0.125\n",
      "Done with epoch 239 in 4.938877820968628s\n",
      "loss:   2.739297389984131,   acc:  0.28125\n",
      "loss:   2.3423960208892822,   acc:  0.1875\n",
      "Done with epoch 240 in 5.027911186218262s\n",
      "loss:   2.3239877223968506,   acc:  0.34375\n",
      "Done with epoch 241 in 5.04588508605957s\n",
      "loss:   3.1275477409362793,   acc:  0.1875\n",
      "Done with epoch 242 in 4.955717086791992s\n",
      "loss:   3.062312602996826,   acc:  0.21875\n",
      "loss:   2.8283424377441406,   acc:  0.25\n",
      "Done with epoch 243 in 5.0428900718688965s\n",
      "loss:   3.2934274673461914,   acc:  0.125\n",
      "Done with epoch 244 in 4.943998098373413s\n",
      "loss:   2.673496961593628,   acc:  0.34375\n",
      "loss:   2.69793963432312,   acc:  0.3125\n",
      "Done with epoch 245 in 5.112409353256226s\n",
      "loss:   2.8616864681243896,   acc:  0.15625\n",
      "Done with epoch 246 in 5.11028528213501s\n",
      "loss:   2.5730056762695312,   acc:  0.21875\n",
      "Done with epoch 247 in 5.021477937698364s\n",
      "loss:   2.753390312194824,   acc:  0.1875\n",
      "loss:   2.236358165740967,   acc:  0.28125\n",
      "Done with epoch 248 in 5.128479957580566s\n",
      "loss:   2.943751335144043,   acc:  0.21875\n",
      "Done with epoch 249 in 5.122375011444092s\n",
      "loss:   2.9547014236450195,   acc:  0.125\n",
      "loss:   2.6288652420043945,   acc:  0.34375\n",
      "Done with epoch 250 in 5.152158737182617s\n",
      "loss:   3.2159039974212646,   acc:  0.21875\n",
      "Done with epoch 251 in 5.205706596374512s\n",
      "loss:   2.7210402488708496,   acc:  0.28125\n",
      "Done with epoch 252 in 5.132394552230835s\n",
      "loss:   2.3241214752197266,   acc:  0.34375\n",
      "loss:   2.740992784500122,   acc:  0.21875\n",
      "Done with epoch 253 in 4.972009897232056s\n",
      "loss:   2.2232606410980225,   acc:  0.34375\n",
      "Done with epoch 254 in 5.049569845199585s\n",
      "loss:   2.6324872970581055,   acc:  0.1875\n",
      "loss:   2.359445095062256,   acc:  0.15625\n",
      "Saved model at /home/acauligi/cs_234/project/mlopt-micp/mlopt_free_flyer_20200629_1010.pt\n",
      "Done with epoch 255 in 4.99421763420105s\n",
      "loss:   2.7762362957000732,   acc:  0.21875\n",
      "Done with epoch 256 in 5.027210235595703s\n",
      "loss:   2.6765661239624023,   acc:  0.3125\n",
      "loss:   2.979429006576538,   acc:  0.25\n",
      "Done with epoch 257 in 5.061869859695435s\n",
      "loss:   2.9894466400146484,   acc:  0.1875\n",
      "Done with epoch 258 in 4.9886956214904785s\n",
      "loss:   2.388089895248413,   acc:  0.28125\n",
      "Done with epoch 259 in 5.091334342956543s\n",
      "loss:   2.8459675312042236,   acc:  0.28125\n",
      "loss:   3.1289401054382324,   acc:  0.1875\n",
      "Done with epoch 260 in 5.0978968143463135s\n",
      "loss:   2.0562655925750732,   acc:  0.375\n",
      "Done with epoch 261 in 5.005185127258301s\n",
      "loss:   2.8229219913482666,   acc:  0.25\n",
      "loss:   2.6024930477142334,   acc:  0.40625\n",
      "Done with epoch 262 in 5.013770580291748s\n",
      "loss:   2.633917808532715,   acc:  0.1875\n",
      "Done with epoch 263 in 5.002206087112427s\n",
      "loss:   3.1581318378448486,   acc:  0.3125\n",
      "Done with epoch 264 in 4.992176294326782s\n",
      "loss:   3.0577878952026367,   acc:  0.28125\n",
      "loss:   3.1083033084869385,   acc:  0.28125\n",
      "Done with epoch 265 in 5.033766508102417s\n",
      "loss:   2.3578732013702393,   acc:  0.3125\n",
      "Done with epoch 266 in 4.883650064468384s\n",
      "loss:   2.712691307067871,   acc:  0.3125\n",
      "loss:   2.752344846725464,   acc:  0.25\n",
      "Done with epoch 267 in 4.967092037200928s\n",
      "loss:   3.0469377040863037,   acc:  0.21875\n",
      "Done with epoch 268 in 4.907479524612427s\n",
      "loss:   2.2494208812713623,   acc:  0.40625\n",
      "Done with epoch 269 in 5.040841341018677s\n",
      "loss:   2.53359055519104,   acc:  0.28125\n",
      "loss:   2.4294073581695557,   acc:  0.25\n",
      "Done with epoch 270 in 5.007689476013184s\n",
      "loss:   2.4537100791931152,   acc:  0.28125\n",
      "Done with epoch 271 in 5.051609039306641s\n",
      "loss:   2.7493817806243896,   acc:  0.25\n",
      "loss:   2.3061578273773193,   acc:  0.34375\n",
      "Done with epoch 272 in 4.9826555252075195s\n",
      "loss:   2.8221702575683594,   acc:  0.21875\n",
      "Done with epoch 273 in 5.062253475189209s\n",
      "loss:   2.4374454021453857,   acc:  0.375\n",
      "Done with epoch 274 in 5.176906585693359s\n",
      "loss:   2.4506356716156006,   acc:  0.21875\n",
      "loss:   2.6748850345611572,   acc:  0.3125\n",
      "Done with epoch 275 in 5.042035102844238s\n",
      "loss:   2.860602378845215,   acc:  0.34375\n",
      "Done with epoch 276 in 5.045517206192017s\n",
      "loss:   2.5265614986419678,   acc:  0.25\n",
      "Saved model at /home/acauligi/cs_234/project/mlopt-micp/mlopt_free_flyer_20200629_1010.pt\n",
      "loss:   2.707247495651245,   acc:  0.1875\n",
      "Done with epoch 277 in 5.068215608596802s\n",
      "loss:   2.9991278648376465,   acc:  0.21875\n",
      "Done with epoch 278 in 5.132288455963135s\n",
      "loss:   2.9816770553588867,   acc:  0.28125\n",
      "Done with epoch 279 in 5.06245756149292s\n",
      "loss:   2.7872836589813232,   acc:  0.15625\n",
      "loss:   3.2079648971557617,   acc:  0.21875\n",
      "Done with epoch 280 in 5.017646789550781s\n",
      "loss:   2.6370601654052734,   acc:  0.3125\n",
      "Done with epoch 281 in 5.126186370849609s\n",
      "loss:   2.296926498413086,   acc:  0.28125\n",
      "loss:   2.603391408920288,   acc:  0.4375\n",
      "Done with epoch 282 in 5.109579086303711s\n",
      "loss:   2.5332131385803223,   acc:  0.34375\n",
      "Done with epoch 283 in 5.110998630523682s\n",
      "loss:   2.753866672515869,   acc:  0.3125\n",
      "Done with epoch 284 in 4.963807106018066s\n",
      "loss:   2.9523046016693115,   acc:  0.1875\n",
      "loss:   2.585343837738037,   acc:  0.3125\n",
      "Done with epoch 285 in 5.080325365066528s\n",
      "loss:   3.0685133934020996,   acc:  0.21875\n",
      "Done with epoch 286 in 5.028088331222534s\n",
      "loss:   2.8012328147888184,   acc:  0.25\n",
      "loss:   2.499336004257202,   acc:  0.25\n",
      "Done with epoch 287 in 4.998802185058594s\n",
      "loss:   2.719588041305542,   acc:  0.1875\n",
      "Done with epoch 288 in 5.1059064865112305s\n",
      "loss:   3.2865850925445557,   acc:  0.15625\n",
      "loss:   2.949634313583374,   acc:  0.28125\n",
      "Done with epoch 289 in 5.060859441757202s\n",
      "loss:   3.175671339035034,   acc:  0.28125\n",
      "Done with epoch 290 in 5.102459669113159s\n",
      "loss:   2.8946762084960938,   acc:  0.25\n",
      "Done with epoch 291 in 5.022612571716309s\n",
      "loss:   2.7235567569732666,   acc:  0.21875\n",
      "loss:   2.983811855316162,   acc:  0.125\n",
      "Done with epoch 292 in 5.033644199371338s\n",
      "loss:   2.7403759956359863,   acc:  0.3125\n",
      "Done with epoch 293 in 5.085479259490967s\n",
      "loss:   3.11348032951355,   acc:  0.28125\n",
      "loss:   2.56626558303833,   acc:  0.25\n",
      "Done with epoch 294 in 5.038938522338867s\n",
      "loss:   2.5200657844543457,   acc:  0.25\n",
      "Done with epoch 295 in 4.974822044372559s\n",
      "loss:   2.917457103729248,   acc:  0.21875\n",
      "Done with epoch 296 in 5.153918266296387s\n",
      "loss:   2.5511202812194824,   acc:  0.34375\n",
      "loss:   2.6346025466918945,   acc:  0.21875\n",
      "Done with epoch 297 in 5.102951765060425s\n",
      "loss:   2.8939359188079834,   acc:  0.21875\n",
      "Saved model at /home/acauligi/cs_234/project/mlopt-micp/mlopt_free_flyer_20200629_1010.pt\n",
      "Done with epoch 298 in 5.106355428695679s\n",
      "loss:   2.874793291091919,   acc:  0.1875\n",
      "loss:   3.0495262145996094,   acc:  0.25\n",
      "Done with epoch 299 in 5.265572547912598s\n",
      "loss:   2.5109167098999023,   acc:  0.28125\n",
      "Done with epoch 300 in 5.160993337631226s\n",
      "loss:   2.57053279876709,   acc:  0.28125\n",
      "Done with epoch 301 in 5.072131633758545s\n",
      "loss:   2.6078240871429443,   acc:  0.1875\n",
      "loss:   2.5152413845062256,   acc:  0.25\n",
      "Done with epoch 302 in 5.162129163742065s\n",
      "loss:   2.6088039875030518,   acc:  0.34375\n",
      "Done with epoch 303 in 5.162085771560669s\n",
      "loss:   2.8220057487487793,   acc:  0.15625\n",
      "loss:   2.8444652557373047,   acc:  0.25\n",
      "Done with epoch 304 in 5.181936979293823s\n",
      "loss:   2.6071085929870605,   acc:  0.3125\n",
      "Done with epoch 305 in 5.115296840667725s\n",
      "loss:   3.083617687225342,   acc:  0.09375\n",
      "Done with epoch 306 in 5.031941175460815s\n",
      "loss:   2.6887054443359375,   acc:  0.1875\n",
      "loss:   2.7855615615844727,   acc:  0.28125\n",
      "Done with epoch 307 in 5.191375732421875s\n",
      "loss:   2.7321252822875977,   acc:  0.3125\n",
      "Done with epoch 308 in 5.14402174949646s\n",
      "loss:   2.752408027648926,   acc:  0.21875\n",
      "loss:   2.283935546875,   acc:  0.34375\n",
      "Done with epoch 309 in 4.985757112503052s\n",
      "loss:   2.505836248397827,   acc:  0.21875\n",
      "Done with epoch 310 in 4.9632368087768555s\n",
      "loss:   2.5141170024871826,   acc:  0.25\n",
      "Done with epoch 311 in 4.983545303344727s\n",
      "loss:   3.2098939418792725,   acc:  0.25\n",
      "loss:   1.9841748476028442,   acc:  0.40625\n",
      "Done with epoch 312 in 5.127145767211914s\n",
      "loss:   2.512389659881592,   acc:  0.5\n",
      "Done with epoch 313 in 5.1014244556427s\n",
      "loss:   2.852001667022705,   acc:  0.21875\n",
      "loss:   2.720806837081909,   acc:  0.25\n",
      "Done with epoch 314 in 5.093614101409912s\n",
      "loss:   3.031625509262085,   acc:  0.15625\n",
      "Done with epoch 315 in 5.045155048370361s\n",
      "loss:   2.6402978897094727,   acc:  0.1875\n",
      "loss:   2.429642915725708,   acc:  0.125\n",
      "Done with epoch 316 in 5.172857284545898s\n",
      "loss:   2.942065477371216,   acc:  0.21875\n",
      "Done with epoch 317 in 5.139682769775391s\n",
      "loss:   2.663283109664917,   acc:  0.28125\n",
      "Done with epoch 318 in 5.1572840213775635s\n",
      "loss:   3.1286706924438477,   acc:  0.28125\n",
      "loss:   2.6277480125427246,   acc:  0.28125\n",
      "Saved model at /home/acauligi/cs_234/project/mlopt-micp/mlopt_free_flyer_20200629_1010.pt\n",
      "Done with epoch 319 in 5.207791328430176s\n",
      "loss:   3.2035775184631348,   acc:  0.15625\n",
      "Done with epoch 320 in 5.113110542297363s\n",
      "loss:   2.651254177093506,   acc:  0.28125\n",
      "loss:   2.5892906188964844,   acc:  0.15625\n",
      "Done with epoch 321 in 5.131179332733154s\n",
      "loss:   2.451842784881592,   acc:  0.21875\n",
      "Done with epoch 322 in 5.043490648269653s\n",
      "loss:   2.961672067642212,   acc:  0.21875\n",
      "Done with epoch 323 in 4.9901416301727295s\n",
      "loss:   2.729553461074829,   acc:  0.09375\n",
      "loss:   2.2899789810180664,   acc:  0.3125\n",
      "Done with epoch 324 in 4.939563751220703s\n",
      "loss:   3.087432622909546,   acc:  0.1875\n",
      "Done with epoch 325 in 4.999345541000366s\n",
      "loss:   2.767646551132202,   acc:  0.125\n",
      "loss:   2.7417495250701904,   acc:  0.3125\n",
      "Done with epoch 326 in 5.05203914642334s\n",
      "loss:   2.5455780029296875,   acc:  0.34375\n",
      "Done with epoch 327 in 4.981140851974487s\n",
      "loss:   2.429645538330078,   acc:  0.25\n",
      "Done with epoch 328 in 5.097053527832031s\n",
      "loss:   2.8598899841308594,   acc:  0.25\n",
      "loss:   2.6039586067199707,   acc:  0.15625\n",
      "Done with epoch 329 in 5.068870782852173s\n",
      "loss:   2.437371253967285,   acc:  0.28125\n",
      "Done with epoch 330 in 4.9024457931518555s\n",
      "loss:   2.610366106033325,   acc:  0.21875\n",
      "loss:   2.6464269161224365,   acc:  0.3125\n",
      "Done with epoch 331 in 5.032483816146851s\n",
      "loss:   3.3413515090942383,   acc:  0.125\n",
      "Done with epoch 332 in 4.919940233230591s\n",
      "loss:   2.4215686321258545,   acc:  0.3125\n",
      "Done with epoch 333 in 4.9853880405426025s\n",
      "loss:   2.943542003631592,   acc:  0.15625\n",
      "loss:   2.6862659454345703,   acc:  0.25\n",
      "Done with epoch 334 in 4.978858947753906s\n",
      "loss:   2.6179282665252686,   acc:  0.21875\n",
      "Done with epoch 335 in 4.93618631362915s\n",
      "loss:   2.2480108737945557,   acc:  0.40625\n",
      "loss:   2.5237784385681152,   acc:  0.21875\n",
      "Done with epoch 336 in 5.0204877853393555s\n",
      "loss:   2.2061374187469482,   acc:  0.25\n",
      "Done with epoch 337 in 4.995055198669434s\n",
      "loss:   2.61928391456604,   acc:  0.40625\n",
      "Done with epoch 338 in 4.9744744300842285s\n",
      "loss:   2.673015594482422,   acc:  0.25\n",
      "loss:   2.950821876525879,   acc:  0.21875\n",
      "Done with epoch 339 in 5.064340591430664s\n",
      "loss:   3.445443630218506,   acc:  0.15625\n",
      "Done with epoch 340 in 5.010711193084717s\n",
      "loss:   2.898456335067749,   acc:  0.1875\n",
      "Saved model at /home/acauligi/cs_234/project/mlopt-micp/mlopt_free_flyer_20200629_1010.pt\n",
      "loss:   2.7779951095581055,   acc:  0.1875\n",
      "Done with epoch 341 in 4.999638319015503s\n",
      "loss:   2.8455796241760254,   acc:  0.3125\n",
      "Done with epoch 342 in 5.016416072845459s\n",
      "loss:   2.379743814468384,   acc:  0.375\n",
      "loss:   2.5729334354400635,   acc:  0.21875\n",
      "Done with epoch 343 in 5.0620410442352295s\n",
      "loss:   2.384735584259033,   acc:  0.28125\n",
      "Done with epoch 344 in 4.935365200042725s\n",
      "loss:   3.1797139644622803,   acc:  0.15625\n",
      "Done with epoch 345 in 4.982427358627319s\n",
      "loss:   2.422663688659668,   acc:  0.3125\n",
      "loss:   2.476935625076294,   acc:  0.28125\n",
      "Done with epoch 346 in 4.990244388580322s\n",
      "loss:   2.623633623123169,   acc:  0.25\n",
      "Done with epoch 347 in 4.989434003829956s\n",
      "loss:   2.1828243732452393,   acc:  0.25\n",
      "loss:   2.6330339908599854,   acc:  0.28125\n",
      "Done with epoch 348 in 4.9885499477386475s\n",
      "loss:   2.4788196086883545,   acc:  0.1875\n",
      "Done with epoch 349 in 4.911555528640747s\n",
      "loss:   3.090763807296753,   acc:  0.21875\n",
      "Done with epoch 350 in 5.060176610946655s\n",
      "loss:   2.310068368911743,   acc:  0.21875\n",
      "loss:   2.6847145557403564,   acc:  0.28125\n",
      "Done with epoch 351 in 5.195709228515625s\n",
      "loss:   2.644052267074585,   acc:  0.375\n",
      "Done with epoch 352 in 5.191845178604126s\n",
      "loss:   2.5162391662597656,   acc:  0.25\n",
      "loss:   2.928974151611328,   acc:  0.28125\n",
      "Done with epoch 353 in 5.009624481201172s\n",
      "loss:   2.978043556213379,   acc:  0.15625\n",
      "Done with epoch 354 in 4.94859766960144s\n",
      "loss:   3.216352701187134,   acc:  0.125\n",
      "Done with epoch 355 in 5.158047914505005s\n",
      "loss:   2.643798828125,   acc:  0.25\n",
      "loss:   2.649515151977539,   acc:  0.28125\n",
      "Done with epoch 356 in 5.18082332611084s\n",
      "loss:   2.315849781036377,   acc:  0.21875\n",
      "Done with epoch 357 in 5.237201929092407s\n",
      "loss:   2.9223804473876953,   acc:  0.125\n",
      "loss:   2.631561756134033,   acc:  0.3125\n",
      "Done with epoch 358 in 5.024371862411499s\n",
      "loss:   2.3317387104034424,   acc:  0.375\n",
      "Done with epoch 359 in 4.951134443283081s\n",
      "loss:   2.6984992027282715,   acc:  0.28125\n",
      "Done with epoch 360 in 5.097370624542236s\n",
      "loss:   2.3930978775024414,   acc:  0.21875\n",
      "loss:   2.6413652896881104,   acc:  0.1875\n",
      "Done with epoch 361 in 5.043718576431274s\n",
      "loss:   2.4105241298675537,   acc:  0.25\n",
      "Saved model at /home/acauligi/cs_234/project/mlopt-micp/mlopt_free_flyer_20200629_1010.pt\n",
      "Done with epoch 362 in 4.987635374069214s\n",
      "loss:   2.94856595993042,   acc:  0.1875\n",
      "loss:   2.6105785369873047,   acc:  0.21875\n",
      "Done with epoch 363 in 5.158367395401001s\n",
      "loss:   2.391350746154785,   acc:  0.25\n",
      "Done with epoch 364 in 5.087490081787109s\n",
      "loss:   2.8763887882232666,   acc:  0.25\n",
      "Done with epoch 365 in 5.204100847244263s\n",
      "loss:   2.2304906845092773,   acc:  0.40625\n",
      "loss:   2.3914244174957275,   acc:  0.25\n",
      "Done with epoch 366 in 5.133772373199463s\n",
      "loss:   2.068708658218384,   acc:  0.28125\n",
      "Done with epoch 367 in 5.142950773239136s\n",
      "loss:   2.9620823860168457,   acc:  0.375\n",
      "loss:   2.2402963638305664,   acc:  0.34375\n",
      "Done with epoch 368 in 5.159602403640747s\n",
      "loss:   2.7152552604675293,   acc:  0.25\n",
      "Done with epoch 369 in 5.169438123703003s\n",
      "loss:   2.588383913040161,   acc:  0.40625\n",
      "Done with epoch 370 in 5.09688925743103s\n",
      "loss:   2.346870183944702,   acc:  0.28125\n",
      "loss:   2.348398447036743,   acc:  0.28125\n",
      "Done with epoch 371 in 5.107115983963013s\n",
      "loss:   2.7487170696258545,   acc:  0.21875\n",
      "Done with epoch 372 in 5.074099779129028s\n",
      "loss:   2.3851215839385986,   acc:  0.46875\n",
      "loss:   2.7937090396881104,   acc:  0.1875\n",
      "Done with epoch 373 in 4.97092080116272s\n",
      "loss:   2.8978118896484375,   acc:  0.15625\n",
      "Done with epoch 374 in 5.101565837860107s\n",
      "loss:   2.345777988433838,   acc:  0.25\n",
      "loss:   2.6875619888305664,   acc:  0.25\n",
      "Done with epoch 375 in 5.045952081680298s\n",
      "loss:   3.028777837753296,   acc:  0.28125\n",
      "Done with epoch 376 in 4.964463710784912s\n",
      "loss:   2.98921799659729,   acc:  0.15625\n",
      "Done with epoch 377 in 4.972158193588257s\n",
      "loss:   2.614400863647461,   acc:  0.40625\n",
      "loss:   2.725883722305298,   acc:  0.21875\n",
      "Done with epoch 378 in 5.002880573272705s\n",
      "loss:   3.388669013977051,   acc:  0.15625\n",
      "Done with epoch 379 in 4.967027425765991s\n",
      "loss:   2.7107245922088623,   acc:  0.3125\n",
      "loss:   2.614652633666992,   acc:  0.40625\n",
      "Done with epoch 380 in 5.004737138748169s\n",
      "loss:   3.46612286567688,   acc:  0.15625\n",
      "Done with epoch 381 in 5.034615993499756s\n",
      "loss:   2.374605417251587,   acc:  0.28125\n",
      "Done with epoch 382 in 5.069502353668213s\n",
      "loss:   2.6886518001556396,   acc:  0.34375\n",
      "loss:   2.6623871326446533,   acc:  0.15625\n",
      "Saved model at /home/acauligi/cs_234/project/mlopt-micp/mlopt_free_flyer_20200629_1010.pt\n",
      "Done with epoch 383 in 5.121006727218628s\n",
      "loss:   2.5696797370910645,   acc:  0.21875\n",
      "Done with epoch 384 in 5.140544891357422s\n",
      "loss:   2.683985948562622,   acc:  0.28125\n",
      "loss:   2.62669038772583,   acc:  0.1875\n",
      "Done with epoch 385 in 5.26321816444397s\n",
      "loss:   3.07460355758667,   acc:  0.21875\n",
      "Done with epoch 386 in 5.171207427978516s\n",
      "loss:   2.577423334121704,   acc:  0.1875\n",
      "Done with epoch 387 in 5.121025323867798s\n",
      "loss:   2.957568407058716,   acc:  0.28125\n",
      "loss:   2.885815143585205,   acc:  0.28125\n",
      "Done with epoch 388 in 5.238195419311523s\n",
      "loss:   3.010477066040039,   acc:  0.09375\n",
      "Done with epoch 389 in 5.1808552742004395s\n",
      "loss:   2.5502116680145264,   acc:  0.125\n",
      "loss:   2.4206526279449463,   acc:  0.25\n",
      "Done with epoch 390 in 5.094033479690552s\n",
      "loss:   2.61212420463562,   acc:  0.21875\n",
      "Done with epoch 391 in 5.087798833847046s\n",
      "loss:   2.7473628520965576,   acc:  0.28125\n",
      "Done with epoch 392 in 5.165833950042725s\n",
      "loss:   2.293344259262085,   acc:  0.3125\n",
      "loss:   2.8294289112091064,   acc:  0.3125\n",
      "Done with epoch 393 in 5.170703887939453s\n",
      "loss:   2.6123743057250977,   acc:  0.1875\n",
      "Done with epoch 394 in 4.949689626693726s\n",
      "loss:   2.4130136966705322,   acc:  0.25\n",
      "loss:   2.5166447162628174,   acc:  0.34375\n",
      "Done with epoch 395 in 5.227716684341431s\n",
      "loss:   2.8106491565704346,   acc:  0.1875\n",
      "Done with epoch 396 in 5.001319885253906s\n",
      "loss:   2.310976028442383,   acc:  0.40625\n",
      "Done with epoch 397 in 5.068819046020508s\n",
      "loss:   2.7496743202209473,   acc:  0.28125\n",
      "loss:   2.625601053237915,   acc:  0.21875\n",
      "Done with epoch 398 in 4.967092514038086s\n",
      "loss:   2.6224608421325684,   acc:  0.28125\n",
      "Done with epoch 399 in 5.0568859577178955s\n",
      "loss:   1.9727439880371094,   acc:  0.40625\n",
      "loss:   2.4751691818237305,   acc:  0.1875\n",
      "Done with epoch 400 in 5.143722772598267s\n",
      "loss:   3.406822443008423,   acc:  0.15625\n",
      "Done with epoch 401 in 5.0130932331085205s\n",
      "loss:   2.839003324508667,   acc:  0.3125\n",
      "loss:   2.583617687225342,   acc:  0.28125\n",
      "Done with epoch 402 in 5.0877203941345215s\n",
      "loss:   2.984614372253418,   acc:  0.21875\n",
      "Done with epoch 403 in 5.078808307647705s\n",
      "loss:   3.2220261096954346,   acc:  0.25\n",
      "Done with epoch 404 in 5.019426107406616s\n",
      "loss:   2.800386667251587,   acc:  0.1875\n",
      "Saved model at /home/acauligi/cs_234/project/mlopt-micp/mlopt_free_flyer_20200629_1010.pt\n",
      "loss:   2.53067684173584,   acc:  0.28125\n",
      "Done with epoch 405 in 4.990589141845703s\n",
      "loss:   2.782792568206787,   acc:  0.3125\n",
      "Done with epoch 406 in 4.949987888336182s\n",
      "loss:   2.5686886310577393,   acc:  0.3125\n",
      "loss:   3.302475929260254,   acc:  0.1875\n",
      "Done with epoch 407 in 5.1034159660339355s\n",
      "loss:   2.528172254562378,   acc:  0.15625\n",
      "Done with epoch 408 in 5.123835325241089s\n",
      "loss:   2.3098347187042236,   acc:  0.3125\n",
      "Done with epoch 409 in 5.013452529907227s\n",
      "loss:   2.3272836208343506,   acc:  0.375\n",
      "loss:   2.716387987136841,   acc:  0.28125\n",
      "Done with epoch 410 in 4.968379497528076s\n",
      "loss:   2.533397912979126,   acc:  0.21875\n",
      "Done with epoch 411 in 4.980355262756348s\n",
      "loss:   2.711697578430176,   acc:  0.34375\n",
      "loss:   2.2755861282348633,   acc:  0.1875\n",
      "Done with epoch 412 in 5.027624845504761s\n",
      "loss:   2.7771968841552734,   acc:  0.25\n",
      "Done with epoch 413 in 4.984028577804565s\n",
      "loss:   2.7192275524139404,   acc:  0.1875\n",
      "Done with epoch 414 in 4.931584596633911s\n",
      "loss:   2.304577589035034,   acc:  0.3125\n",
      "loss:   2.311736822128296,   acc:  0.34375\n",
      "Done with epoch 415 in 4.967973470687866s\n",
      "loss:   2.8391945362091064,   acc:  0.15625\n",
      "Done with epoch 416 in 5.006667137145996s\n",
      "loss:   2.9332783222198486,   acc:  0.21875\n",
      "loss:   2.4371421337127686,   acc:  0.25\n",
      "Done with epoch 417 in 5.070236921310425s\n",
      "loss:   2.505561590194702,   acc:  0.25\n",
      "Done with epoch 418 in 4.978457689285278s\n",
      "loss:   2.6701526641845703,   acc:  0.34375\n",
      "Done with epoch 419 in 4.908264636993408s\n",
      "loss:   2.5570075511932373,   acc:  0.34375\n",
      "loss:   2.507956027984619,   acc:  0.25\n",
      "Done with epoch 420 in 5.003337860107422s\n",
      "loss:   2.260420799255371,   acc:  0.34375\n",
      "Done with epoch 421 in 5.0042033195495605s\n",
      "loss:   2.7885732650756836,   acc:  0.3125\n",
      "loss:   2.62028169631958,   acc:  0.125\n",
      "Done with epoch 422 in 5.0207741260528564s\n",
      "loss:   2.497683525085449,   acc:  0.1875\n",
      "Done with epoch 423 in 4.973882675170898s\n",
      "loss:   2.5472524166107178,   acc:  0.375\n",
      "Done with epoch 424 in 4.973044157028198s\n",
      "loss:   2.3682713508605957,   acc:  0.3125\n",
      "loss:   2.6436760425567627,   acc:  0.1875\n",
      "Done with epoch 425 in 4.9758405685424805s\n",
      "loss:   2.215083122253418,   acc:  0.3125\n",
      "Saved model at /home/acauligi/cs_234/project/mlopt-micp/mlopt_free_flyer_20200629_1010.pt\n",
      "Done with epoch 426 in 5.026661157608032s\n",
      "loss:   2.5707337856292725,   acc:  0.34375\n",
      "loss:   3.0322864055633545,   acc:  0.21875\n",
      "Done with epoch 427 in 5.148890495300293s\n",
      "loss:   2.679508686065674,   acc:  0.15625\n",
      "Done with epoch 428 in 4.9468042850494385s\n",
      "loss:   2.4055492877960205,   acc:  0.1875\n",
      "loss:   2.707587480545044,   acc:  0.28125\n",
      "Done with epoch 429 in 5.254046201705933s\n",
      "loss:   2.411107063293457,   acc:  0.28125\n",
      "Done with epoch 430 in 5.099453926086426s\n",
      "loss:   2.696486473083496,   acc:  0.25\n",
      "Done with epoch 431 in 5.103216171264648s\n",
      "loss:   2.46317195892334,   acc:  0.3125\n",
      "loss:   2.3769283294677734,   acc:  0.34375\n",
      "Done with epoch 432 in 5.207927465438843s\n",
      "loss:   2.5943944454193115,   acc:  0.21875\n",
      "Done with epoch 433 in 5.145700693130493s\n",
      "loss:   2.5776851177215576,   acc:  0.25\n",
      "loss:   2.417889356613159,   acc:  0.28125\n",
      "Done with epoch 434 in 5.016892194747925s\n",
      "loss:   2.466909885406494,   acc:  0.28125\n",
      "Done with epoch 435 in 5.058956623077393s\n",
      "loss:   2.569477081298828,   acc:  0.3125\n",
      "Done with epoch 436 in 5.128091335296631s\n",
      "loss:   2.36452579498291,   acc:  0.34375\n",
      "loss:   2.3136308193206787,   acc:  0.28125\n",
      "Done with epoch 437 in 5.2152626514434814s\n",
      "loss:   2.92217755317688,   acc:  0.1875\n",
      "Done with epoch 438 in 5.078261137008667s\n",
      "loss:   2.6770925521850586,   acc:  0.21875\n",
      "loss:   2.247924327850342,   acc:  0.28125\n",
      "Done with epoch 439 in 5.107160806655884s\n",
      "loss:   2.486452579498291,   acc:  0.3125\n",
      "Done with epoch 440 in 4.95046854019165s\n",
      "loss:   2.0462186336517334,   acc:  0.40625\n",
      "Done with epoch 441 in 5.225787878036499s\n",
      "loss:   2.2267611026763916,   acc:  0.3125\n",
      "loss:   2.546358585357666,   acc:  0.25\n",
      "Done with epoch 442 in 5.164273500442505s\n",
      "loss:   2.606574773788452,   acc:  0.3125\n",
      "Done with epoch 443 in 5.114038944244385s\n",
      "loss:   2.7014214992523193,   acc:  0.21875\n",
      "loss:   2.495492935180664,   acc:  0.21875\n",
      "Done with epoch 444 in 5.085344076156616s\n",
      "loss:   2.40090274810791,   acc:  0.21875\n",
      "Done with epoch 445 in 5.225351572036743s\n",
      "loss:   2.8156087398529053,   acc:  0.25\n",
      "Done with epoch 446 in 5.040025949478149s\n",
      "loss:   2.911365032196045,   acc:  0.1875\n",
      "loss:   2.1943085193634033,   acc:  0.375\n",
      "Saved model at /home/acauligi/cs_234/project/mlopt-micp/mlopt_free_flyer_20200629_1010.pt\n",
      "Done with epoch 447 in 5.02292799949646s\n",
      "loss:   2.6215574741363525,   acc:  0.34375\n",
      "Done with epoch 448 in 5.006988048553467s\n",
      "loss:   2.847127914428711,   acc:  0.15625\n",
      "loss:   2.2085866928100586,   acc:  0.40625\n",
      "Done with epoch 449 in 5.03499960899353s\n",
      "loss:   2.1999847888946533,   acc:  0.3125\n",
      "Done with epoch 450 in 5.140763521194458s\n",
      "loss:   2.8089945316314697,   acc:  0.34375\n",
      "Done with epoch 451 in 5.02065634727478s\n",
      "loss:   2.695760488510132,   acc:  0.25\n",
      "loss:   2.702932357788086,   acc:  0.3125\n",
      "Done with epoch 452 in 5.021036148071289s\n",
      "loss:   2.488051176071167,   acc:  0.4375\n",
      "Done with epoch 453 in 4.96693229675293s\n",
      "loss:   2.7145612239837646,   acc:  0.21875\n",
      "loss:   3.050290584564209,   acc:  0.1875\n",
      "Done with epoch 454 in 5.161977767944336s\n",
      "loss:   2.4643306732177734,   acc:  0.34375\n",
      "Done with epoch 455 in 5.1702775955200195s\n",
      "loss:   2.407588481903076,   acc:  0.21875\n",
      "Done with epoch 456 in 5.090834379196167s\n",
      "loss:   2.393711566925049,   acc:  0.3125\n",
      "loss:   2.321061849594116,   acc:  0.3125\n",
      "Done with epoch 457 in 5.064273118972778s\n",
      "loss:   2.8453481197357178,   acc:  0.3125\n",
      "Done with epoch 458 in 4.977411985397339s\n",
      "loss:   2.803896427154541,   acc:  0.09375\n",
      "loss:   2.4493134021759033,   acc:  0.3125\n",
      "Done with epoch 459 in 5.233730792999268s\n",
      "loss:   2.6342897415161133,   acc:  0.28125\n",
      "Done with epoch 460 in 5.129217863082886s\n",
      "loss:   2.3411052227020264,   acc:  0.34375\n",
      "loss:   2.18218731880188,   acc:  0.28125\n",
      "Done with epoch 461 in 5.001602411270142s\n",
      "loss:   2.8259060382843018,   acc:  0.25\n",
      "Done with epoch 462 in 4.996822118759155s\n",
      "loss:   2.568999767303467,   acc:  0.21875\n",
      "Done with epoch 463 in 5.071228265762329s\n",
      "loss:   2.42610502243042,   acc:  0.25\n",
      "loss:   2.5099265575408936,   acc:  0.28125\n",
      "Done with epoch 464 in 5.03580117225647s\n",
      "loss:   2.8552494049072266,   acc:  0.125\n",
      "Done with epoch 465 in 5.045942544937134s\n",
      "loss:   3.2518556118011475,   acc:  0.21875\n",
      "loss:   2.407991409301758,   acc:  0.4375\n",
      "Done with epoch 466 in 5.212773084640503s\n",
      "loss:   2.7488808631896973,   acc:  0.25\n",
      "Done with epoch 467 in 5.125376224517822s\n",
      "loss:   2.550474166870117,   acc:  0.15625\n",
      "Done with epoch 468 in 5.102255344390869s\n",
      "loss:   2.615140199661255,   acc:  0.25\n",
      "Saved model at /home/acauligi/cs_234/project/mlopt-micp/mlopt_free_flyer_20200629_1010.pt\n",
      "loss:   2.5087838172912598,   acc:  0.3125\n",
      "Done with epoch 469 in 5.060903787612915s\n",
      "loss:   2.4307806491851807,   acc:  0.3125\n",
      "Done with epoch 470 in 4.991709232330322s\n",
      "loss:   2.888014793395996,   acc:  0.28125\n",
      "loss:   2.3551762104034424,   acc:  0.3125\n",
      "Done with epoch 471 in 5.1483659744262695s\n",
      "loss:   2.709200859069824,   acc:  0.1875\n",
      "Done with epoch 472 in 5.057414293289185s\n",
      "loss:   2.711334228515625,   acc:  0.09375\n",
      "Done with epoch 473 in 4.944911241531372s\n",
      "loss:   2.683530330657959,   acc:  0.25\n",
      "loss:   2.988206386566162,   acc:  0.28125\n",
      "Done with epoch 474 in 5.161872625350952s\n",
      "loss:   2.667776584625244,   acc:  0.15625\n",
      "Done with epoch 475 in 5.071658372879028s\n",
      "loss:   2.3184115886688232,   acc:  0.375\n",
      "loss:   2.0249996185302734,   acc:  0.375\n",
      "Done with epoch 476 in 5.103780269622803s\n",
      "loss:   2.5193207263946533,   acc:  0.21875\n",
      "Done with epoch 477 in 5.1273884773254395s\n",
      "loss:   2.701897144317627,   acc:  0.375\n",
      "Done with epoch 478 in 5.109935283660889s\n",
      "loss:   2.4835281372070312,   acc:  0.34375\n",
      "loss:   2.6920535564422607,   acc:  0.28125\n",
      "Done with epoch 479 in 5.135948181152344s\n",
      "loss:   2.735138416290283,   acc:  0.21875\n",
      "Done with epoch 480 in 5.230022668838501s\n",
      "loss:   2.6495842933654785,   acc:  0.3125\n",
      "loss:   2.393803596496582,   acc:  0.21875\n",
      "Done with epoch 481 in 5.123417854309082s\n",
      "loss:   2.3063645362854004,   acc:  0.3125\n",
      "Done with epoch 482 in 5.096606731414795s\n",
      "loss:   2.2905616760253906,   acc:  0.46875\n",
      "Done with epoch 483 in 5.055483818054199s\n",
      "loss:   2.5544674396514893,   acc:  0.125\n",
      "loss:   2.6845755577087402,   acc:  0.25\n",
      "Done with epoch 484 in 5.003089666366577s\n",
      "loss:   2.62155818939209,   acc:  0.28125\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-6-bf6376d984a4>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mmlopt_ts_obj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtraining_params\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'TRAINING_ITERATIONS'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m500\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mmlopt_ts_obj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/cs_234/project/mlopt-micp/solvers/mlopt_ff.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self, verbose)\u001b[0m\n\u001b[1;32m    187\u001b[0m                 \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    188\u001b[0m                 \u001b[0;31m#torch.nn.utils.clip_grad_norm(model.parameters(),0.1)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 189\u001b[0;31m                 \u001b[0mopt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    190\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    191\u001b[0m                 \u001b[0;31m# print statistics\\n\",\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/cs_234/project/mlopt-micp/mlopt/lib/python3.6/site-packages/torch/autograd/grad_mode.py\u001b[0m in \u001b[0;36mdecorate_context\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     13\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mdecorate_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mdecorate_context\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/cs_234/project/mlopt-micp/mlopt/lib/python3.6/site-packages/torch/optim/adam.py\u001b[0m in \u001b[0;36mstep\u001b[0;34m(self, closure)\u001b[0m\n\u001b[1;32m     97\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     98\u001b[0m                 \u001b[0;31m# Decay the first and second moment running average coefficient\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 99\u001b[0;31m                 \u001b[0mexp_avg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmul_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbeta1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgrad\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0malpha\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mbeta1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    100\u001b[0m                 \u001b[0mexp_avg_sq\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmul_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbeta2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maddcmul_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgrad\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mbeta2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    101\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mamsgrad\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "mlopt_ts_obj.training_params['TRAINING_ITERATIONS'] = 500\n",
    "mlopt_ts_obj.train(verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prob_params = {}\n",
    "idx = np.random.randint(test_data[1].shape[0])\n",
    "\n",
    "p_test = test_data[0]\n",
    "for k in p_test.keys():\n",
    "    prob_params[k] = p_test[k][idx]\n",
    "prob_success, cost, total_time, n_evals = mlopt_ts_obj.forward(prob_params)\n",
    "\n",
    "if prob_success:\n",
    "    print(cost)\n",
    "else:\n",
    "    print('Failed')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prob_success, true_cost, solve_time, optvals = mlopt_ts_obj.problem.solve_micp(prob_params)\n",
    "\n",
    "true_cost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x0 = train_data[0]['x0'][idx]\n",
    "n_obs = mlopt_ts_obj.problem.n_obs\n",
    "posmin, posmax = mlopt_ts_obj.problem.posmin, mlopt_ts_obj.problem.posmax\n",
    "\n",
    "obstacles = []\n",
    "for ii_obs in range(n_obs):\n",
    "    obs = train_data[0]['obstacles'][idx][:,ii_obs]\n",
    "    obstacles.append(obs)\n",
    "\n",
    "X = optvals[0]\n",
    "\n",
    "plt.axes()\n",
    "for obstacle in obstacles:\n",
    "    rectangle = plt.Rectangle((obstacle[0], obstacle[2]), \\\n",
    "                              obstacle[1]-obstacle[0], obstacle[3]-obstacle[2], \\\n",
    "                             fc='red', ec='blue')\n",
    "    plt.gca().add_patch(rectangle)\n",
    "    plt.axis('scaled')\n",
    "\n",
    "for ii in range(mlopt_ts_obj.problem.N):\n",
    "    circle = plt.Circle((X[0,ii],X[1,ii]), 0.04, fc='blue',ec=\"green\")\n",
    "    plt.gca().add_patch(circle)\n",
    "\n",
    "ax = plt.gca()\n",
    "ax.margins(0)\n",
    "ax.set(xlim=(posmin[0],posmax[0]), ylim=(posmin[1],posmax[1]))\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mlopt",
   "language": "python",
   "name": "mlopt"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
