{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "import numpy as np\n",
    "import cvxpy as cp\n",
    "\n",
    "from free_flyer.free_flyer import FreeFlyer\n",
    "import pickle, os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#load train/test data\n",
    "prob = FreeFlyer() #use default config, pass different config file oth.\n",
    "config_fn = './free_flyer/config/default.p'\n",
    "\n",
    "config_file = open(config_fn,'rb')\n",
    "dataset_name, _, _ = pickle.load(config_file); config_file.close()\n",
    "\n",
    "relative_path = os.getcwd()\n",
    "dataset_fn = relative_path + '/free_flyer/data/' + dataset_name\n",
    "\n",
    "train_file = open(dataset_fn+'/train.p','rb')\n",
    "# p_train, x_train, u_train, y_train, c_train, times_train = pickle.load(train_file)\n",
    "train_data = pickle.load(train_file)\n",
    "train_file.close()\n",
    "\n",
    "test_file = open(dataset_fn+'/test.p','rb')\n",
    "# p_test, x_test, u_test, y_test, c_test, times_test = pickle.load(test_file)\n",
    "test_data = pickle.load(test_file)\n",
    "test_file.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# test MLOPT solver"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "64988\n"
     ]
    }
   ],
   "source": [
    "from solvers.mlopt import MLOPT\n",
    "\n",
    "system = 'free_flyer'\n",
    "prob_features = ['x0', 'obstacles']\n",
    "mlopt_obj = MLOPT(system, prob, prob_features)\n",
    "\n",
    "n_features = 36\n",
    "mlopt_obj.construct_strategies(n_features, train_data)\n",
    "print(mlopt_obj.n_strategies)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mlopt_obj.setup_network()\n",
    "\n",
    "fn_saved = 'models/mlopt_free_flyer_20200624_1449.pt'\n",
    "fn_saved = 'models/mlopt_free_flyer_20200629_1323.pt'\n",
    "mlopt_obj.load_network(fn_saved)\n",
    "\n",
    "mlopt_obj.model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mlopt_obj.training_params['TRAINING_ITERATIONS'] = 100\n",
    "mlopt_obj.train()\n",
    "print(mlopt_obj.model_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prob_params = {}\n",
    "idx = np.random.randint(test_data[1].shape[0])\n",
    "\n",
    "p_test = test_data[0]\n",
    "for k in p_test.keys():\n",
    "    prob_params[k] = p_test[k][idx]\n",
    "prob_success, cost, total_time, n_evals = mlopt_obj.forward(prob_params)\n",
    "\n",
    "if prob_success:\n",
    "    print(cost)\n",
    "else:\n",
    "    print('Failed')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prob_success, true_cost, solve_time, optvals = mlopt_obj.problem.solve_micp(prob_params)\n",
    "\n",
    "true_cost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_succ = 0\n",
    "count = 0\n",
    "\n",
    "for ii in range(100):\n",
    "    idx = np.random.randint(train_data[1].shape[0])\n",
    "    prob_params = {}\n",
    "    p_test = train_data[0]\n",
    "    for k in p_test.keys():\n",
    "        prob_params[k] = p_test[k][idx]\n",
    "    prob_success, cost, total_time, n_evals = mlopt_obj.forward(prob_params)\n",
    "\n",
    "    count += 1\n",
    "    if prob_success:\n",
    "        n_succ += 1\n",
    "\n",
    "print(float(n_succ)/ float(count))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "idx = np.random.randint(train_data[1].shape[0])\n",
    "x0 = train_data[0]['x0'][idx]\n",
    "n_obs = train_data[0]['obstacles'][idx].shape[1]\n",
    "posmin, posmax = mlopt_obj.problem.posmin, mlopt_obj.problem.posmax\n",
    "\n",
    "obstacles = []\n",
    "for ii_obs in range(n_obs):\n",
    "    obs = train_data[0]['obstacles'][idx][:,ii_obs]\n",
    "    obstacles.append(obs)\n",
    "\n",
    "if len(obstacles) is n_obs:\n",
    "    plt.axes()\n",
    "    for obstacle in obstacles:\n",
    "        rectangle = plt.Rectangle((obstacle[0], obstacle[2]), \\\n",
    "                                  obstacle[1]-obstacle[0], obstacle[3]-obstacle[2], \\\n",
    "                                 fc='red', ec='blue')\n",
    "        plt.gca().add_patch(rectangle)\n",
    "        plt.axis('scaled')\n",
    "\n",
    "    circle = plt.Circle((x0[0],x0[1]), 0.04, fc='blue',ec=\"green\")\n",
    "    plt.gca().add_patch(circle)    \n",
    "\n",
    "    ax = plt.gca()\n",
    "    ax.margins(0)\n",
    "    ax.set(xlim=(posmin[0],posmax[0]), ylim=(posmin[1],posmax[1]))\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# test task-specific MLOPT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from solvers.mlopt_ff import MLOPT_FF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> /home/acauligi/cs_234/project/mlopt-micp/solvers/mlopt_ff.py(98)construct_strategies()\n",
      "-> if obs_strat not in self.strategy_dict.keys():\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "(Pdb)  obs_strrat\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*** NameError: name 'obs_strrat' is not defined\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "(Pdb)  obs_strat\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 2, 3, 33, 34, 35, 65, 66, 67, 97, 98, 99, 129, 130, 131)\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "(Pdb)  c\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> /home/acauligi/cs_234/project/mlopt-micp/solvers/mlopt_ff.py(96)construct_strategies()\n",
      "-> pdb.set_trace()\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "(Pdb)  obs_strat\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5, 6, 37, 38, 69, 70, 101, 102, 133, 134)\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "(Pdb)  c\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> /home/acauligi/cs_234/project/mlopt-micp/solvers/mlopt_ff.py(98)construct_strategies()\n",
      "-> if obs_strat not in self.strategy_dict.keys():\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "(Pdb)  obs_strat\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(9, 10, 41, 42, 73, 74, 105, 106, 137, 138)\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "(Pdb)  c\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> /home/acauligi/cs_234/project/mlopt-micp/solvers/mlopt_ff.py(96)construct_strategies()\n",
      "-> pdb.set_trace()\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "(Pdb)  obs_strat\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(13, 14, 45, 46, 77, 78, 79, 109, 110, 111, 141, 142, 143)\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "(Pdb)  q\n"
     ]
    },
    {
     "ename": "BdbQuit",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mBdbQuit\u001b[0m                                   Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-30-85545b829760>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mn_features\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m36\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mprob\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_obs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0mmlopt_ts_obj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconstruct_strategies\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_features\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_data\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmlopt_ts_obj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_strategies\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/cs_234/project/mlopt-micp/solvers/mlopt_ff.py\u001b[0m in \u001b[0;36mconstruct_strategies\u001b[0;34m(self, n_features, train_data, test_data)\u001b[0m\n\u001b[1;32m     94\u001b[0m                 \u001b[0my_true\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mY\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mii\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mii_obs\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mii_obs\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_y\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     95\u001b[0m                 \u001b[0mobs_strat\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtuple\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobs_strats\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mii_obs\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 96\u001b[0;31m                 \u001b[0mpdb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_trace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     97\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     98\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mobs_strat\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstrategy_dict\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeys\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/cs_234/project/mlopt-micp/solvers/mlopt_ff.py\u001b[0m in \u001b[0;36mconstruct_strategies\u001b[0;34m(self, n_features, train_data, test_data)\u001b[0m\n\u001b[1;32m     94\u001b[0m                 \u001b[0my_true\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mY\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mii\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mii_obs\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mii_obs\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_y\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     95\u001b[0m                 \u001b[0mobs_strat\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtuple\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobs_strats\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mii_obs\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 96\u001b[0;31m                 \u001b[0mpdb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_trace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     97\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     98\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mobs_strat\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstrategy_dict\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeys\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/bdb.py\u001b[0m in \u001b[0;36mtrace_dispatch\u001b[0;34m(self, frame, event, arg)\u001b[0m\n\u001b[1;32m     46\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0;31m# None\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     47\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mevent\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'line'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 48\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdispatch_line\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mframe\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     49\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mevent\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'call'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     50\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdispatch_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mframe\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0marg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/bdb.py\u001b[0m in \u001b[0;36mdispatch_line\u001b[0;34m(self, frame)\u001b[0m\n\u001b[1;32m     65\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstop_here\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mframe\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbreak_here\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mframe\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0muser_line\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mframe\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 67\u001b[0;31m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mquitting\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;32mraise\u001b[0m \u001b[0mBdbQuit\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     68\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrace_dispatch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mBdbQuit\u001b[0m: "
     ]
    }
   ],
   "source": [
    "system = 'free_flyer'\n",
    "prob_features = ['x0', 'obstacles']\n",
    "mlopt_ts_obj = MLOPT_FF(system, prob, prob_features)\n",
    "\n",
    "n_features = 36 + prob.n_obs\n",
    "mlopt_ts_obj.construct_strategies(n_features, train_data)\n",
    "print(mlopt_ts_obj.n_strategies)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "979\n"
     ]
    }
   ],
   "source": [
    "prob = FreeFlyer() #use default config, pass different config file oth.\n",
    "system = 'free_flyer'\n",
    "prob_features = ['x0', 'obstacles']\n",
    "mlopt_ts_obj = MLOPT_FF(system, prob, prob_features)\n",
    "\n",
    "n_features = 36 + prob.n_obs\n",
    "mlopt_ts_obj.construct_strategies(n_features, train_data)\n",
    "print(mlopt_ts_obj.n_strategies)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "FFNet(\n",
       "  (activation): ReLU()\n",
       "  (layers): ModuleList(\n",
       "    (0): Linear(in_features=44, out_features=32, bias=True)\n",
       "    (1): Linear(in_features=32, out_features=32, bias=True)\n",
       "    (2): Linear(in_features=32, out_features=32, bias=True)\n",
       "    (3): Linear(in_features=32, out_features=979, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mlopt_ts_obj.setup_network()\n",
    "\n",
    "# mlopt_ts_obj.load_network(fn_saved)\n",
    "\n",
    "mlopt_ts_obj.model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss:   3.262643575668335,   acc:  0.3125\n",
      "Done with epoch 0 in 2.3208892345428467s\n",
      "loss:   3.04656982421875,   acc:  0.375\n",
      "Done with epoch 1 in 2.3787901401519775s\n",
      "loss:   3.608766794204712,   acc:  0.34375\n",
      "loss:   3.9276769161224365,   acc:  0.125\n",
      "Done with epoch 2 in 2.450430154800415s\n",
      "loss:   2.361124277114868,   acc:  0.4375\n",
      "Done with epoch 3 in 2.366983652114868s\n",
      "loss:   3.0866901874542236,   acc:  0.4375\n",
      "loss:   3.332869529724121,   acc:  0.28125\n",
      "Done with epoch 4 in 2.3948206901550293s\n",
      "loss:   2.893850326538086,   acc:  0.40625\n",
      "Done with epoch 5 in 2.3331923484802246s\n",
      "loss:   2.7058939933776855,   acc:  0.375\n",
      "Done with epoch 6 in 2.357694149017334s\n",
      "loss:   2.658712148666382,   acc:  0.5\n",
      "loss:   2.716782569885254,   acc:  0.40625\n",
      "Done with epoch 7 in 2.361222267150879s\n",
      "loss:   2.936413049697876,   acc:  0.4375\n",
      "Done with epoch 8 in 2.3057427406311035s\n",
      "loss:   3.538048267364502,   acc:  0.1875\n",
      "loss:   2.945460319519043,   acc:  0.375\n",
      "Done with epoch 9 in 2.3763668537139893s\n",
      "loss:   3.057093620300293,   acc:  0.375\n",
      "Done with epoch 10 in 2.321671724319458s\n",
      "loss:   3.336411476135254,   acc:  0.40625\n",
      "Done with epoch 11 in 2.3638370037078857s\n",
      "loss:   3.8229541778564453,   acc:  0.25\n",
      "loss:   3.3695268630981445,   acc:  0.21875\n",
      "Done with epoch 12 in 2.4175431728363037s\n",
      "loss:   2.8293330669403076,   acc:  0.25\n",
      "Done with epoch 13 in 2.4090890884399414s\n",
      "loss:   3.10375714302063,   acc:  0.28125\n",
      "loss:   3.258641242980957,   acc:  0.28125\n",
      "Done with epoch 14 in 2.4483938217163086s\n",
      "loss:   3.083580732345581,   acc:  0.28125\n",
      "Done with epoch 15 in 2.3430137634277344s\n",
      "loss:   2.6927337646484375,   acc:  0.34375\n",
      "Done with epoch 16 in 2.294461965560913s\n",
      "loss:   2.965632677078247,   acc:  0.375\n",
      "loss:   2.852602243423462,   acc:  0.3125\n",
      "Done with epoch 17 in 2.40472674369812s\n",
      "loss:   3.483346939086914,   acc:  0.28125\n",
      "Done with epoch 18 in 2.3188767433166504s\n",
      "loss:   3.2032814025878906,   acc:  0.21875\n",
      "loss:   3.107170820236206,   acc:  0.34375\n",
      "Done with epoch 19 in 2.376861333847046s\n",
      "loss:   3.07674503326416,   acc:  0.25\n",
      "Done with epoch 20 in 2.3516933917999268s\n",
      "loss:   2.2954869270324707,   acc:  0.53125\n",
      "Saved model at /home/acauligi/cs_234/project/mlopt-micp/mlopt_free_flyer_20200629_1521.pt\n",
      "Done with epoch 21 in 2.3111400604248047s\n",
      "loss:   3.5123403072357178,   acc:  0.28125\n",
      "loss:   2.9210612773895264,   acc:  0.3125\n",
      "Done with epoch 22 in 2.3967092037200928s\n",
      "loss:   3.357936143875122,   acc:  0.28125\n",
      "Done with epoch 23 in 2.33880352973938s\n",
      "loss:   3.3210175037384033,   acc:  0.3125\n",
      "loss:   2.9192276000976562,   acc:  0.3125\n",
      "Done with epoch 24 in 2.3836960792541504s\n",
      "loss:   2.9927096366882324,   acc:  0.34375\n",
      "Done with epoch 25 in 2.3352911472320557s\n",
      "loss:   2.6590027809143066,   acc:  0.3125\n",
      "Done with epoch 26 in 2.2964344024658203s\n",
      "loss:   3.379535436630249,   acc:  0.1875\n",
      "loss:   3.906414270401001,   acc:  0.1875\n",
      "Done with epoch 27 in 2.3666203022003174s\n",
      "loss:   3.203387498855591,   acc:  0.1875\n",
      "Done with epoch 28 in 2.311100482940674s\n",
      "loss:   3.1996378898620605,   acc:  0.3125\n",
      "loss:   3.223506450653076,   acc:  0.3125\n",
      "Done with epoch 29 in 2.3673441410064697s\n",
      "loss:   3.01668643951416,   acc:  0.21875\n",
      "Done with epoch 30 in 2.334237575531006s\n",
      "loss:   3.1999130249023438,   acc:  0.25\n",
      "loss:   3.125657320022583,   acc:  0.25\n",
      "Done with epoch 31 in 2.4425246715545654s\n",
      "loss:   3.3516130447387695,   acc:  0.25\n",
      "Done with epoch 32 in 2.358394145965576s\n",
      "loss:   2.626255750656128,   acc:  0.4375\n",
      "Done with epoch 33 in 2.3715553283691406s\n",
      "loss:   3.4031715393066406,   acc:  0.25\n",
      "loss:   2.9082939624786377,   acc:  0.34375\n",
      "Done with epoch 34 in 2.4302852153778076s\n",
      "loss:   3.1789324283599854,   acc:  0.15625\n",
      "Done with epoch 35 in 2.3101377487182617s\n",
      "loss:   2.794551372528076,   acc:  0.4375\n",
      "loss:   3.5035364627838135,   acc:  0.28125\n",
      "Done with epoch 36 in 2.344135046005249s\n",
      "loss:   3.2308261394500732,   acc:  0.3125\n",
      "Done with epoch 37 in 2.3743412494659424s\n",
      "loss:   3.288707733154297,   acc:  0.34375\n",
      "Done with epoch 38 in 2.3580644130706787s\n",
      "loss:   2.9280402660369873,   acc:  0.375\n",
      "loss:   2.6349570751190186,   acc:  0.53125\n",
      "Done with epoch 39 in 2.416100025177002s\n",
      "loss:   3.088711738586426,   acc:  0.3125\n",
      "Done with epoch 40 in 2.278822183609009s\n",
      "loss:   3.299203395843506,   acc:  0.28125\n",
      "loss:   2.8992016315460205,   acc:  0.25\n",
      "Done with epoch 41 in 2.380708694458008s\n",
      "loss:   3.421567440032959,   acc:  0.34375\n",
      "Saved model at /home/acauligi/cs_234/project/mlopt-micp/mlopt_free_flyer_20200629_1521.pt\n",
      "Done with epoch 42 in 2.3318209648132324s\n",
      "loss:   3.2573983669281006,   acc:  0.28125\n",
      "Done with epoch 43 in 2.3237192630767822s\n",
      "loss:   3.289858102798462,   acc:  0.21875\n",
      "loss:   3.089155912399292,   acc:  0.3125\n",
      "Done with epoch 44 in 2.3642961978912354s\n",
      "loss:   2.85623836517334,   acc:  0.3125\n",
      "Done with epoch 45 in 2.373685121536255s\n",
      "loss:   3.2602968215942383,   acc:  0.25\n",
      "loss:   3.571601390838623,   acc:  0.28125\n",
      "Done with epoch 46 in 2.3914284706115723s\n",
      "loss:   2.847914695739746,   acc:  0.46875\n",
      "Done with epoch 47 in 2.326463460922241s\n",
      "loss:   3.024219512939453,   acc:  0.28125\n",
      "Done with epoch 48 in 2.342249631881714s\n",
      "loss:   3.293027877807617,   acc:  0.21875\n",
      "loss:   3.383805751800537,   acc:  0.28125\n",
      "Done with epoch 49 in 2.3895301818847656s\n",
      "loss:   3.2690014839172363,   acc:  0.3125\n",
      "Done with epoch 50 in 2.3810975551605225s\n",
      "loss:   3.0881359577178955,   acc:  0.28125\n",
      "loss:   3.302288293838501,   acc:  0.21875\n",
      "Done with epoch 51 in 2.3948750495910645s\n",
      "loss:   2.9775171279907227,   acc:  0.53125\n",
      "Done with epoch 52 in 2.3612325191497803s\n",
      "loss:   3.2466673851013184,   acc:  0.28125\n",
      "Done with epoch 53 in 2.375393867492676s\n",
      "loss:   2.8977601528167725,   acc:  0.34375\n",
      "loss:   3.4115705490112305,   acc:  0.25\n",
      "Done with epoch 54 in 2.409417152404785s\n",
      "loss:   3.0094974040985107,   acc:  0.375\n",
      "Done with epoch 55 in 2.3546853065490723s\n",
      "loss:   2.792609691619873,   acc:  0.34375\n",
      "loss:   3.323948383331299,   acc:  0.3125\n",
      "Done with epoch 56 in 2.3742544651031494s\n",
      "loss:   2.699888229370117,   acc:  0.34375\n",
      "Done with epoch 57 in 2.342151165008545s\n",
      "loss:   3.5352213382720947,   acc:  0.21875\n",
      "loss:   2.7807106971740723,   acc:  0.28125\n",
      "Done with epoch 58 in 2.38627028465271s\n",
      "loss:   2.924647808074951,   acc:  0.3125\n",
      "Done with epoch 59 in 2.3013648986816406s\n",
      "loss:   3.2994463443756104,   acc:  0.1875\n",
      "Done with epoch 60 in 2.310565710067749s\n",
      "loss:   3.0613365173339844,   acc:  0.3125\n",
      "loss:   2.915595531463623,   acc:  0.34375\n",
      "Done with epoch 61 in 2.389518976211548s\n",
      "loss:   3.455549478530884,   acc:  0.15625\n",
      "Done with epoch 62 in 2.3475725650787354s\n",
      "loss:   3.2794573307037354,   acc:  0.34375\n",
      "loss:   3.4741275310516357,   acc:  0.25\n",
      "Saved model at /home/acauligi/cs_234/project/mlopt-micp/mlopt_free_flyer_20200629_1521.pt\n",
      "Done with epoch 63 in 2.403099298477173s\n",
      "loss:   2.915743827819824,   acc:  0.40625\n",
      "Done with epoch 64 in 2.3631467819213867s\n",
      "loss:   3.6124658584594727,   acc:  0.15625\n",
      "Done with epoch 65 in 2.3425958156585693s\n",
      "loss:   2.905897855758667,   acc:  0.34375\n",
      "loss:   3.285644054412842,   acc:  0.1875\n",
      "Done with epoch 66 in 2.3639252185821533s\n",
      "loss:   3.123668909072876,   acc:  0.28125\n",
      "Done with epoch 67 in 2.261517286300659s\n",
      "loss:   3.188109874725342,   acc:  0.28125\n",
      "loss:   3.469489097595215,   acc:  0.28125\n",
      "Done with epoch 68 in 2.35701584815979s\n",
      "loss:   3.2766330242156982,   acc:  0.1875\n",
      "Done with epoch 69 in 2.3111324310302734s\n",
      "loss:   3.334507942199707,   acc:  0.3125\n",
      "Done with epoch 70 in 2.3069305419921875s\n",
      "loss:   3.0433170795440674,   acc:  0.25\n",
      "loss:   3.430351734161377,   acc:  0.28125\n",
      "Done with epoch 71 in 2.3922181129455566s\n",
      "loss:   3.3294591903686523,   acc:  0.34375\n",
      "Done with epoch 72 in 2.342745780944824s\n",
      "loss:   3.0328423976898193,   acc:  0.46875\n",
      "loss:   3.02537202835083,   acc:  0.28125\n",
      "Done with epoch 73 in 2.38759183883667s\n",
      "loss:   3.183911085128784,   acc:  0.375\n",
      "Done with epoch 74 in 2.354619026184082s\n",
      "loss:   3.5228142738342285,   acc:  0.25\n",
      "Done with epoch 75 in 2.325962781906128s\n",
      "loss:   3.7617833614349365,   acc:  0.25\n",
      "loss:   3.307889223098755,   acc:  0.25\n",
      "Done with epoch 76 in 2.3930327892303467s\n",
      "loss:   2.965562582015991,   acc:  0.375\n",
      "Done with epoch 77 in 2.2847189903259277s\n",
      "loss:   3.044761896133423,   acc:  0.375\n",
      "loss:   2.563783884048462,   acc:  0.3125\n",
      "Done with epoch 78 in 2.3806920051574707s\n",
      "loss:   2.8819925785064697,   acc:  0.375\n",
      "Done with epoch 79 in 2.3582849502563477s\n",
      "loss:   2.3721001148223877,   acc:  0.34375\n",
      "Done with epoch 80 in 2.3365886211395264s\n",
      "loss:   2.585061550140381,   acc:  0.46875\n",
      "loss:   3.200887680053711,   acc:  0.25\n",
      "Done with epoch 81 in 2.34541654586792s\n",
      "loss:   3.3374643325805664,   acc:  0.28125\n",
      "Done with epoch 82 in 2.299146890640259s\n",
      "loss:   3.907150983810425,   acc:  0.21875\n",
      "loss:   3.238842725753784,   acc:  0.3125\n",
      "Done with epoch 83 in 2.3739442825317383s\n",
      "loss:   3.205345869064331,   acc:  0.25\n",
      "Done with epoch 84 in 2.337435245513916s\n",
      "loss:   3.5346741676330566,   acc:  0.34375\n",
      "Saved model at /home/acauligi/cs_234/project/mlopt-micp/mlopt_free_flyer_20200629_1521.pt\n",
      "loss:   2.788250207901001,   acc:  0.25\n",
      "Done with epoch 85 in 2.3985540866851807s\n",
      "loss:   3.2880287170410156,   acc:  0.25\n",
      "Done with epoch 86 in 2.3053314685821533s\n",
      "loss:   2.773854970932007,   acc:  0.3125\n",
      "Done with epoch 87 in 2.288947582244873s\n",
      "loss:   3.4432449340820312,   acc:  0.25\n",
      "loss:   3.32413387298584,   acc:  0.28125\n",
      "Done with epoch 88 in 2.3707001209259033s\n",
      "loss:   3.1444687843322754,   acc:  0.34375\n",
      "Done with epoch 89 in 2.3434486389160156s\n",
      "loss:   2.941575050354004,   acc:  0.34375\n",
      "loss:   3.519684314727783,   acc:  0.21875\n",
      "Done with epoch 90 in 2.4126124382019043s\n",
      "loss:   2.9748451709747314,   acc:  0.34375\n",
      "Done with epoch 91 in 2.3262343406677246s\n",
      "loss:   2.7348766326904297,   acc:  0.40625\n",
      "Done with epoch 92 in 2.3065128326416016s\n",
      "loss:   2.9663243293762207,   acc:  0.34375\n",
      "loss:   2.8666298389434814,   acc:  0.375\n",
      "Done with epoch 93 in 2.349882125854492s\n",
      "loss:   2.881636381149292,   acc:  0.40625\n",
      "Done with epoch 94 in 2.299259901046753s\n",
      "loss:   2.6455442905426025,   acc:  0.5\n",
      "loss:   2.56856632232666,   acc:  0.34375\n",
      "Done with epoch 95 in 2.349497079849243s\n",
      "loss:   2.920400381088257,   acc:  0.21875\n",
      "Done with epoch 96 in 2.3071999549865723s\n",
      "loss:   3.125661611557007,   acc:  0.34375\n",
      "Done with epoch 97 in 2.3195812702178955s\n",
      "loss:   2.6310486793518066,   acc:  0.375\n",
      "loss:   3.1694953441619873,   acc:  0.15625\n",
      "Done with epoch 98 in 2.344789743423462s\n",
      "loss:   3.1206090450286865,   acc:  0.34375\n",
      "Done with epoch 99 in 2.2546815872192383s\n",
      "loss:   2.6588289737701416,   acc:  0.34375\n",
      "loss:   2.961681365966797,   acc:  0.21875\n",
      "Done with epoch 100 in 2.418156623840332s\n",
      "loss:   3.6379919052124023,   acc:  0.3125\n",
      "Done with epoch 101 in 2.3684403896331787s\n",
      "loss:   3.253910541534424,   acc:  0.3125\n",
      "Done with epoch 102 in 2.3658597469329834s\n",
      "loss:   3.2431890964508057,   acc:  0.21875\n",
      "loss:   3.460646390914917,   acc:  0.25\n",
      "Done with epoch 103 in 2.380316734313965s\n",
      "loss:   3.6760191917419434,   acc:  0.34375\n",
      "Done with epoch 104 in 2.3139963150024414s\n",
      "loss:   3.27347469329834,   acc:  0.1875\n",
      "loss:   3.5878982543945312,   acc:  0.1875\n",
      "Done with epoch 105 in 2.3572232723236084s\n",
      "loss:   2.8442888259887695,   acc:  0.375\n",
      "Saved model at /home/acauligi/cs_234/project/mlopt-micp/mlopt_free_flyer_20200629_1521.pt\n",
      "Done with epoch 106 in 2.33634090423584s\n",
      "loss:   3.6200876235961914,   acc:  0.28125\n",
      "Done with epoch 107 in 2.3758528232574463s\n",
      "loss:   2.536383867263794,   acc:  0.5\n",
      "loss:   3.268622636795044,   acc:  0.28125\n",
      "Done with epoch 108 in 2.3894572257995605s\n",
      "loss:   3.1912667751312256,   acc:  0.21875\n",
      "Done with epoch 109 in 2.282170534133911s\n",
      "loss:   2.3582046031951904,   acc:  0.5\n",
      "loss:   2.809945583343506,   acc:  0.46875\n",
      "Done with epoch 110 in 2.3449864387512207s\n",
      "loss:   3.678591251373291,   acc:  0.21875\n",
      "Done with epoch 111 in 2.335212230682373s\n",
      "loss:   2.8239095211029053,   acc:  0.3125\n",
      "Done with epoch 112 in 2.303523302078247s\n",
      "loss:   2.698578119277954,   acc:  0.46875\n",
      "loss:   2.9137303829193115,   acc:  0.28125\n",
      "Done with epoch 113 in 2.3620896339416504s\n",
      "loss:   3.2752602100372314,   acc:  0.125\n",
      "Done with epoch 114 in 2.2491464614868164s\n",
      "loss:   3.1912851333618164,   acc:  0.21875\n",
      "loss:   2.72475266456604,   acc:  0.40625\n",
      "Done with epoch 115 in 2.2734127044677734s\n",
      "loss:   2.5912673473358154,   acc:  0.28125\n",
      "Done with epoch 116 in 2.2630646228790283s\n",
      "loss:   3.3566761016845703,   acc:  0.375\n",
      "loss:   3.2080726623535156,   acc:  0.21875\n",
      "Done with epoch 117 in 2.330540180206299s\n",
      "loss:   2.633786678314209,   acc:  0.34375\n",
      "Done with epoch 118 in 2.2378668785095215s\n",
      "loss:   2.777738571166992,   acc:  0.40625\n",
      "Done with epoch 119 in 2.2636020183563232s\n",
      "loss:   3.4537017345428467,   acc:  0.28125\n",
      "loss:   2.829310655593872,   acc:  0.25\n",
      "Done with epoch 120 in 2.3231894969940186s\n",
      "loss:   3.170651912689209,   acc:  0.28125\n",
      "Done with epoch 121 in 2.2816572189331055s\n",
      "loss:   2.783802032470703,   acc:  0.34375\n",
      "loss:   3.2325127124786377,   acc:  0.15625\n",
      "Done with epoch 122 in 2.303166151046753s\n",
      "loss:   2.9935054779052734,   acc:  0.34375\n",
      "Done with epoch 123 in 2.2854814529418945s\n",
      "loss:   3.1152632236480713,   acc:  0.3125\n",
      "Done with epoch 124 in 2.2674593925476074s\n",
      "loss:   2.727932929992676,   acc:  0.28125\n",
      "loss:   3.142078399658203,   acc:  0.25\n",
      "Done with epoch 125 in 2.317915201187134s\n",
      "loss:   3.2771403789520264,   acc:  0.28125\n",
      "Done with epoch 126 in 2.272189140319824s\n",
      "loss:   3.1276350021362305,   acc:  0.28125\n",
      "loss:   4.039418697357178,   acc:  0.15625\n",
      "Saved model at /home/acauligi/cs_234/project/mlopt-micp/mlopt_free_flyer_20200629_1521.pt\n",
      "Done with epoch 127 in 2.3357105255126953s\n",
      "loss:   3.088005781173706,   acc:  0.3125\n",
      "Done with epoch 128 in 2.2722079753875732s\n",
      "loss:   2.873783826828003,   acc:  0.34375\n",
      "Done with epoch 129 in 2.3237829208374023s\n",
      "loss:   2.836453914642334,   acc:  0.3125\n",
      "loss:   2.2569055557250977,   acc:  0.40625\n",
      "Done with epoch 130 in 2.3968331813812256s\n",
      "loss:   3.182173728942871,   acc:  0.3125\n",
      "Done with epoch 131 in 2.3484771251678467s\n",
      "loss:   2.9319233894348145,   acc:  0.34375\n",
      "loss:   3.073859214782715,   acc:  0.28125\n",
      "Done with epoch 132 in 2.415071487426758s\n",
      "loss:   3.388516664505005,   acc:  0.28125\n",
      "Done with epoch 133 in 2.455399990081787s\n",
      "loss:   2.6678900718688965,   acc:  0.40625\n",
      "Done with epoch 134 in 2.377385377883911s\n",
      "loss:   2.753760576248169,   acc:  0.40625\n",
      "loss:   2.924731969833374,   acc:  0.40625\n",
      "Done with epoch 135 in 2.4489810466766357s\n",
      "loss:   2.789494037628174,   acc:  0.375\n",
      "Done with epoch 136 in 2.3896610736846924s\n",
      "loss:   3.3892884254455566,   acc:  0.21875\n",
      "loss:   2.6483325958251953,   acc:  0.5\n",
      "Done with epoch 137 in 2.3981287479400635s\n",
      "loss:   3.29380464553833,   acc:  0.25\n",
      "Done with epoch 138 in 2.306971549987793s\n",
      "loss:   3.476473808288574,   acc:  0.28125\n",
      "Done with epoch 139 in 2.324455499649048s\n",
      "loss:   3.0754547119140625,   acc:  0.25\n",
      "loss:   3.363694667816162,   acc:  0.21875\n",
      "Done with epoch 140 in 2.41841983795166s\n",
      "loss:   3.9599854946136475,   acc:  0.15625\n",
      "Done with epoch 141 in 2.3887572288513184s\n",
      "loss:   3.2575020790100098,   acc:  0.34375\n",
      "loss:   3.2690181732177734,   acc:  0.375\n",
      "Done with epoch 142 in 2.445878267288208s\n",
      "loss:   2.4521501064300537,   acc:  0.40625\n",
      "Done with epoch 143 in 2.373229503631592s\n",
      "loss:   2.657425880432129,   acc:  0.3125\n",
      "loss:   3.0771963596343994,   acc:  0.34375\n",
      "Done with epoch 144 in 2.410695791244507s\n",
      "loss:   3.4004898071289062,   acc:  0.28125\n",
      "Done with epoch 145 in 2.3280489444732666s\n",
      "loss:   2.93218731880188,   acc:  0.28125\n",
      "Done with epoch 146 in 2.375640869140625s\n",
      "loss:   2.520301342010498,   acc:  0.28125\n",
      "loss:   3.5635032653808594,   acc:  0.28125\n",
      "Done with epoch 147 in 2.4389753341674805s\n",
      "loss:   2.9417970180511475,   acc:  0.1875\n",
      "Done with epoch 148 in 2.3257334232330322s\n",
      "loss:   3.0115103721618652,   acc:  0.4375\n",
      "Saved model at /home/acauligi/cs_234/project/mlopt-micp/mlopt_free_flyer_20200629_1521.pt\n",
      "loss:   3.1020257472991943,   acc:  0.21875\n",
      "Done with epoch 149 in 2.318372964859009s\n",
      "loss:   3.615131378173828,   acc:  0.15625\n",
      "Done with epoch 150 in 2.350632905960083s\n",
      "loss:   3.4414000511169434,   acc:  0.1875\n",
      "Done with epoch 151 in 2.343366861343384s\n",
      "loss:   2.834716558456421,   acc:  0.34375\n",
      "loss:   3.1394288539886475,   acc:  0.25\n",
      "Done with epoch 152 in 2.392082929611206s\n",
      "loss:   2.828888416290283,   acc:  0.375\n",
      "Done with epoch 153 in 2.3625898361206055s\n",
      "loss:   2.8246471881866455,   acc:  0.4375\n",
      "loss:   2.8552989959716797,   acc:  0.40625\n",
      "Done with epoch 154 in 2.4019389152526855s\n",
      "loss:   2.4500694274902344,   acc:  0.5\n",
      "Done with epoch 155 in 2.348813056945801s\n",
      "loss:   2.9348838329315186,   acc:  0.21875\n",
      "Done with epoch 156 in 2.33962082862854s\n",
      "loss:   3.409388780593872,   acc:  0.25\n",
      "loss:   3.9253251552581787,   acc:  0.15625\n",
      "Done with epoch 157 in 2.3912410736083984s\n",
      "loss:   3.282325029373169,   acc:  0.25\n",
      "Done with epoch 158 in 2.3325998783111572s\n",
      "loss:   2.753859758377075,   acc:  0.3125\n",
      "loss:   3.132007122039795,   acc:  0.34375\n",
      "Done with epoch 159 in 2.4012041091918945s\n",
      "loss:   2.8614916801452637,   acc:  0.34375\n",
      "Done with epoch 160 in 2.382206439971924s\n",
      "loss:   2.810702085494995,   acc:  0.375\n",
      "Done with epoch 161 in 2.3794968128204346s\n",
      "loss:   2.4276838302612305,   acc:  0.40625\n",
      "loss:   2.185868501663208,   acc:  0.46875\n",
      "Done with epoch 162 in 2.428246259689331s\n",
      "loss:   3.3474135398864746,   acc:  0.25\n",
      "Done with epoch 163 in 2.3631274700164795s\n",
      "loss:   3.2633609771728516,   acc:  0.1875\n",
      "loss:   2.7342426776885986,   acc:  0.34375\n",
      "Done with epoch 164 in 2.3796567916870117s\n",
      "loss:   2.598968267440796,   acc:  0.4375\n",
      "Done with epoch 165 in 2.27589750289917s\n",
      "loss:   3.2109649181365967,   acc:  0.3125\n",
      "Done with epoch 166 in 2.313275098800659s\n",
      "loss:   3.114847183227539,   acc:  0.21875\n",
      "loss:   2.6852598190307617,   acc:  0.4375\n",
      "Done with epoch 167 in 2.4041481018066406s\n",
      "loss:   2.4615094661712646,   acc:  0.28125\n",
      "Done with epoch 168 in 2.354508638381958s\n",
      "loss:   3.5522661209106445,   acc:  0.1875\n",
      "loss:   3.2301442623138428,   acc:  0.3125\n",
      "Done with epoch 169 in 2.392152786254883s\n",
      "loss:   3.1793041229248047,   acc:  0.3125\n",
      "Saved model at /home/acauligi/cs_234/project/mlopt-micp/mlopt_free_flyer_20200629_1521.pt\n",
      "Done with epoch 170 in 2.367004632949829s\n",
      "loss:   2.965437650680542,   acc:  0.375\n",
      "loss:   3.523371934890747,   acc:  0.28125\n",
      "Done with epoch 171 in 2.3845667839050293s\n",
      "loss:   3.058577537536621,   acc:  0.34375\n",
      "Done with epoch 172 in 2.3706350326538086s\n",
      "loss:   3.2505135536193848,   acc:  0.21875\n",
      "Done with epoch 173 in 2.385585069656372s\n",
      "loss:   2.668264150619507,   acc:  0.375\n",
      "loss:   3.147379159927368,   acc:  0.28125\n",
      "Done with epoch 174 in 2.383361339569092s\n",
      "loss:   2.935950994491577,   acc:  0.3125\n",
      "Done with epoch 175 in 2.3566367626190186s\n",
      "loss:   3.2418220043182373,   acc:  0.28125\n",
      "loss:   3.5382609367370605,   acc:  0.15625\n",
      "Done with epoch 176 in 2.409181833267212s\n",
      "loss:   3.0816991329193115,   acc:  0.375\n",
      "Done with epoch 177 in 2.3676578998565674s\n",
      "loss:   2.964773178100586,   acc:  0.40625\n",
      "Done with epoch 178 in 2.3226780891418457s\n",
      "loss:   3.217384099960327,   acc:  0.3125\n",
      "loss:   3.1444830894470215,   acc:  0.25\n",
      "Done with epoch 179 in 2.404465675354004s\n",
      "loss:   2.36686635017395,   acc:  0.46875\n",
      "Done with epoch 180 in 2.368438959121704s\n",
      "loss:   2.925912618637085,   acc:  0.375\n",
      "loss:   2.9978184700012207,   acc:  0.3125\n",
      "Done with epoch 181 in 2.4199750423431396s\n",
      "loss:   2.607426643371582,   acc:  0.4375\n",
      "Done with epoch 182 in 2.3760080337524414s\n",
      "loss:   2.9032740592956543,   acc:  0.375\n",
      "Done with epoch 183 in 2.364567995071411s\n",
      "loss:   3.6941726207733154,   acc:  0.25\n",
      "loss:   3.224088668823242,   acc:  0.21875\n",
      "Done with epoch 184 in 2.4328742027282715s\n",
      "loss:   3.0665273666381836,   acc:  0.34375\n",
      "Done with epoch 185 in 2.327880382537842s\n",
      "loss:   2.7944440841674805,   acc:  0.46875\n",
      "loss:   2.9829418659210205,   acc:  0.3125\n",
      "Done with epoch 186 in 2.3721017837524414s\n",
      "loss:   3.132599115371704,   acc:  0.1875\n",
      "Done with epoch 187 in 2.341566562652588s\n",
      "loss:   3.286510467529297,   acc:  0.34375\n",
      "Done with epoch 188 in 2.3426809310913086s\n",
      "loss:   3.196641445159912,   acc:  0.21875\n",
      "loss:   3.0411641597747803,   acc:  0.375\n",
      "Done with epoch 189 in 2.4465434551239014s\n",
      "loss:   3.0635108947753906,   acc:  0.40625\n",
      "Done with epoch 190 in 2.3761496543884277s\n",
      "loss:   2.6717889308929443,   acc:  0.4375\n",
      "loss:   3.6194908618927,   acc:  0.21875\n",
      "Saved model at /home/acauligi/cs_234/project/mlopt-micp/mlopt_free_flyer_20200629_1521.pt\n",
      "Done with epoch 191 in 2.3994925022125244s\n",
      "loss:   3.3526906967163086,   acc:  0.3125\n",
      "Done with epoch 192 in 2.346768856048584s\n",
      "loss:   3.308830976486206,   acc:  0.3125\n",
      "Done with epoch 193 in 2.3495566844940186s\n",
      "loss:   2.7275328636169434,   acc:  0.375\n",
      "loss:   4.276078224182129,   acc:  0.125\n",
      "Done with epoch 194 in 2.3823866844177246s\n",
      "loss:   2.507845401763916,   acc:  0.5\n",
      "Done with epoch 195 in 2.379693031311035s\n",
      "loss:   3.2212889194488525,   acc:  0.28125\n",
      "loss:   2.8182716369628906,   acc:  0.3125\n",
      "Done with epoch 196 in 2.4253792762756348s\n",
      "loss:   3.149912118911743,   acc:  0.34375\n",
      "Done with epoch 197 in 2.37589430809021s\n",
      "loss:   2.8930699825286865,   acc:  0.40625\n",
      "Done with epoch 198 in 2.3364927768707275s\n",
      "loss:   2.8445916175842285,   acc:  0.46875\n",
      "loss:   2.945288896560669,   acc:  0.28125\n",
      "Done with epoch 199 in 2.423144817352295s\n",
      "loss:   3.238466262817383,   acc:  0.21875\n",
      "Done with epoch 200 in 2.378312110900879s\n",
      "loss:   3.3749608993530273,   acc:  0.21875\n",
      "loss:   2.8425467014312744,   acc:  0.34375\n",
      "Done with epoch 201 in 2.358102798461914s\n",
      "loss:   2.511281967163086,   acc:  0.53125\n",
      "Done with epoch 202 in 2.3176443576812744s\n",
      "loss:   2.652416229248047,   acc:  0.375\n",
      "loss:   2.874469757080078,   acc:  0.375\n",
      "Done with epoch 203 in 2.361807107925415s\n",
      "loss:   2.202914237976074,   acc:  0.4375\n",
      "Done with epoch 204 in 2.355302095413208s\n",
      "loss:   3.161442518234253,   acc:  0.28125\n",
      "Done with epoch 205 in 2.3916096687316895s\n",
      "loss:   3.240976572036743,   acc:  0.21875\n",
      "loss:   3.5553877353668213,   acc:  0.15625\n",
      "Done with epoch 206 in 2.4332568645477295s\n",
      "loss:   2.849360704421997,   acc:  0.375\n",
      "Done with epoch 207 in 2.3667984008789062s\n",
      "loss:   2.7403740882873535,   acc:  0.4375\n",
      "loss:   3.0987322330474854,   acc:  0.1875\n",
      "Done with epoch 208 in 2.367577075958252s\n",
      "loss:   3.014024019241333,   acc:  0.3125\n",
      "Done with epoch 209 in 2.322110652923584s\n",
      "loss:   2.9679787158966064,   acc:  0.3125\n",
      "Done with epoch 210 in 2.3900394439697266s\n",
      "loss:   3.7215635776519775,   acc:  0.15625\n",
      "loss:   3.298870086669922,   acc:  0.3125\n",
      "Done with epoch 211 in 2.392484188079834s\n",
      "loss:   2.5738418102264404,   acc:  0.4375\n",
      "Done with epoch 212 in 2.2699778079986572s\n",
      "loss:   2.424060106277466,   acc:  0.40625\n",
      "Saved model at /home/acauligi/cs_234/project/mlopt-micp/mlopt_free_flyer_20200629_1521.pt\n",
      "loss:   2.815154552459717,   acc:  0.3125\n",
      "Done with epoch 213 in 2.3807287216186523s\n",
      "loss:   2.99967098236084,   acc:  0.34375\n",
      "Done with epoch 214 in 2.3820106983184814s\n",
      "loss:   3.2927255630493164,   acc:  0.28125\n",
      "Done with epoch 215 in 2.3725297451019287s\n",
      "loss:   3.354179859161377,   acc:  0.1875\n",
      "loss:   2.7653415203094482,   acc:  0.28125\n",
      "Done with epoch 216 in 2.40336537361145s\n",
      "loss:   3.0379316806793213,   acc:  0.34375\n",
      "Done with epoch 217 in 2.3482954502105713s\n",
      "loss:   3.0669045448303223,   acc:  0.3125\n",
      "loss:   2.9193809032440186,   acc:  0.375\n",
      "Done with epoch 218 in 2.382627487182617s\n",
      "loss:   3.3656914234161377,   acc:  0.34375\n",
      "Done with epoch 219 in 2.3038454055786133s\n",
      "loss:   3.0859241485595703,   acc:  0.21875\n",
      "Done with epoch 220 in 2.305677652359009s\n",
      "loss:   2.9526519775390625,   acc:  0.25\n",
      "loss:   2.4987735748291016,   acc:  0.40625\n",
      "Done with epoch 221 in 2.405895471572876s\n",
      "loss:   3.0198707580566406,   acc:  0.3125\n",
      "Done with epoch 222 in 2.321294069290161s\n",
      "loss:   2.9992291927337646,   acc:  0.40625\n",
      "loss:   2.822728395462036,   acc:  0.375\n",
      "Done with epoch 223 in 2.4093308448791504s\n",
      "loss:   3.2017369270324707,   acc:  0.1875\n",
      "Done with epoch 224 in 2.358999729156494s\n",
      "loss:   3.230833053588867,   acc:  0.25\n",
      "Done with epoch 225 in 2.375500440597534s\n",
      "loss:   2.8218469619750977,   acc:  0.34375\n",
      "loss:   3.299511671066284,   acc:  0.25\n",
      "Done with epoch 226 in 2.3997950553894043s\n",
      "loss:   2.9958035945892334,   acc:  0.28125\n",
      "Done with epoch 227 in 2.3537776470184326s\n",
      "loss:   3.482945680618286,   acc:  0.25\n",
      "loss:   3.1009068489074707,   acc:  0.21875\n",
      "Done with epoch 228 in 2.398581027984619s\n",
      "loss:   3.0541319847106934,   acc:  0.21875\n",
      "Done with epoch 229 in 2.3400914669036865s\n",
      "loss:   3.6558449268341064,   acc:  0.09375\n",
      "loss:   2.809640407562256,   acc:  0.3125\n",
      "Done with epoch 230 in 2.375854969024658s\n",
      "loss:   2.8768417835235596,   acc:  0.3125\n",
      "Done with epoch 231 in 2.3153388500213623s\n",
      "loss:   3.484386682510376,   acc:  0.3125\n",
      "Done with epoch 232 in 2.3353190422058105s\n",
      "loss:   3.311594247817993,   acc:  0.1875\n",
      "loss:   2.6203248500823975,   acc:  0.375\n",
      "Done with epoch 233 in 2.358166217803955s\n",
      "loss:   3.0046873092651367,   acc:  0.28125\n",
      "Saved model at /home/acauligi/cs_234/project/mlopt-micp/mlopt_free_flyer_20200629_1521.pt\n",
      "Done with epoch 234 in 2.36611008644104s\n",
      "loss:   2.346487283706665,   acc:  0.40625\n",
      "loss:   3.2919716835021973,   acc:  0.25\n",
      "Done with epoch 235 in 2.403871774673462s\n",
      "loss:   3.4038870334625244,   acc:  0.3125\n",
      "Done with epoch 236 in 2.363525867462158s\n",
      "loss:   2.896880626678467,   acc:  0.375\n",
      "Done with epoch 237 in 2.346552848815918s\n",
      "loss:   2.9719948768615723,   acc:  0.4375\n",
      "loss:   2.8590846061706543,   acc:  0.40625\n",
      "Done with epoch 238 in 2.4159815311431885s\n",
      "loss:   3.510838747024536,   acc:  0.3125\n",
      "Done with epoch 239 in 2.383248805999756s\n",
      "loss:   2.8737053871154785,   acc:  0.3125\n",
      "loss:   2.5229692459106445,   acc:  0.5\n",
      "Done with epoch 240 in 2.397174119949341s\n",
      "loss:   2.984144449234009,   acc:  0.28125\n",
      "Done with epoch 241 in 2.2876408100128174s\n",
      "loss:   2.582625389099121,   acc:  0.34375\n",
      "Done with epoch 242 in 2.3262321949005127s\n",
      "loss:   2.474620819091797,   acc:  0.46875\n",
      "loss:   3.5103280544281006,   acc:  0.1875\n",
      "Done with epoch 243 in 2.3808155059814453s\n",
      "loss:   2.6448771953582764,   acc:  0.34375\n",
      "Done with epoch 244 in 2.37258243560791s\n",
      "loss:   3.6033594608306885,   acc:  0.21875\n",
      "loss:   3.4633469581604004,   acc:  0.1875\n",
      "Done with epoch 245 in 2.419616937637329s\n",
      "loss:   2.864229917526245,   acc:  0.34375\n",
      "Done with epoch 246 in 2.3161630630493164s\n",
      "loss:   2.1773386001586914,   acc:  0.46875\n",
      "Done with epoch 247 in 2.281085729598999s\n",
      "loss:   3.2920727729797363,   acc:  0.34375\n",
      "loss:   2.796405076980591,   acc:  0.3125\n",
      "Done with epoch 248 in 2.344111919403076s\n",
      "loss:   3.5158941745758057,   acc:  0.21875\n",
      "Done with epoch 249 in 2.303863525390625s\n",
      "loss:   2.7273504734039307,   acc:  0.4375\n",
      "loss:   3.424093008041382,   acc:  0.125\n",
      "Done with epoch 250 in 2.3619637489318848s\n",
      "loss:   2.9634270668029785,   acc:  0.25\n",
      "Done with epoch 251 in 2.288027763366699s\n",
      "loss:   2.8414406776428223,   acc:  0.34375\n",
      "Done with epoch 252 in 2.3373265266418457s\n",
      "loss:   3.020218849182129,   acc:  0.25\n",
      "loss:   2.8323001861572266,   acc:  0.34375\n",
      "Done with epoch 253 in 2.4017958641052246s\n",
      "loss:   2.9900543689727783,   acc:  0.34375\n",
      "Done with epoch 254 in 2.353201389312744s\n",
      "loss:   3.0500893592834473,   acc:  0.375\n",
      "loss:   3.0408482551574707,   acc:  0.15625\n",
      "Saved model at /home/acauligi/cs_234/project/mlopt-micp/mlopt_free_flyer_20200629_1521.pt\n",
      "Done with epoch 255 in 2.4516968727111816s\n",
      "loss:   2.6665096282958984,   acc:  0.28125\n",
      "Done with epoch 256 in 2.366694927215576s\n",
      "loss:   3.4819552898406982,   acc:  0.21875\n",
      "loss:   3.1971964836120605,   acc:  0.28125\n",
      "Done with epoch 257 in 2.3626163005828857s\n",
      "loss:   3.1351451873779297,   acc:  0.25\n",
      "Done with epoch 258 in 2.3222384452819824s\n",
      "loss:   2.468137741088867,   acc:  0.40625\n",
      "Done with epoch 259 in 2.325747013092041s\n",
      "loss:   2.6322779655456543,   acc:  0.40625\n",
      "loss:   3.862091064453125,   acc:  0.125\n",
      "Done with epoch 260 in 2.4210808277130127s\n",
      "loss:   2.634899139404297,   acc:  0.34375\n",
      "Done with epoch 261 in 2.3557538986206055s\n",
      "loss:   2.8973894119262695,   acc:  0.34375\n",
      "loss:   3.2182300090789795,   acc:  0.25\n",
      "Done with epoch 262 in 2.383408308029175s\n",
      "loss:   2.7084107398986816,   acc:  0.28125\n",
      "Done with epoch 263 in 2.3558034896850586s\n",
      "loss:   3.0883758068084717,   acc:  0.40625\n",
      "Done with epoch 264 in 2.3246243000030518s\n",
      "loss:   3.4356863498687744,   acc:  0.3125\n",
      "loss:   3.2478315830230713,   acc:  0.28125\n",
      "Done with epoch 265 in 2.3434841632843018s\n",
      "loss:   2.6697914600372314,   acc:  0.4375\n",
      "Done with epoch 266 in 2.3868720531463623s\n",
      "loss:   3.297757148742676,   acc:  0.28125\n",
      "loss:   2.863086700439453,   acc:  0.28125\n",
      "Done with epoch 267 in 2.3996541500091553s\n",
      "loss:   2.892016887664795,   acc:  0.3125\n",
      "Done with epoch 268 in 2.3132874965667725s\n",
      "loss:   3.0787394046783447,   acc:  0.3125\n",
      "Done with epoch 269 in 2.375527858734131s\n",
      "loss:   2.7863011360168457,   acc:  0.34375\n",
      "loss:   2.9011471271514893,   acc:  0.3125\n",
      "Done with epoch 270 in 2.441765546798706s\n",
      "loss:   3.2752020359039307,   acc:  0.25\n",
      "Done with epoch 271 in 2.350494384765625s\n",
      "loss:   3.4238779544830322,   acc:  0.28125\n",
      "loss:   3.4556961059570312,   acc:  0.21875\n",
      "Done with epoch 272 in 2.354771614074707s\n",
      "loss:   2.9509079456329346,   acc:  0.21875\n",
      "Done with epoch 273 in 2.291194200515747s\n",
      "loss:   2.930227279663086,   acc:  0.3125\n",
      "Done with epoch 274 in 2.366597890853882s\n",
      "loss:   3.2434144020080566,   acc:  0.3125\n",
      "loss:   3.056002378463745,   acc:  0.3125\n",
      "Done with epoch 275 in 2.4103853702545166s\n",
      "loss:   3.317507028579712,   acc:  0.28125\n",
      "Done with epoch 276 in 2.3556482791900635s\n",
      "loss:   2.815434694290161,   acc:  0.375\n",
      "Saved model at /home/acauligi/cs_234/project/mlopt-micp/mlopt_free_flyer_20200629_1521.pt\n",
      "loss:   3.0141780376434326,   acc:  0.25\n",
      "Done with epoch 277 in 2.3928062915802s\n",
      "loss:   2.938117265701294,   acc:  0.34375\n",
      "Done with epoch 278 in 2.336672067642212s\n",
      "loss:   2.5467331409454346,   acc:  0.375\n",
      "Done with epoch 279 in 2.3254125118255615s\n",
      "loss:   3.2109758853912354,   acc:  0.3125\n",
      "loss:   2.479867458343506,   acc:  0.4375\n",
      "Done with epoch 280 in 2.3917617797851562s\n",
      "loss:   3.085221290588379,   acc:  0.3125\n",
      "Done with epoch 281 in 2.3460047245025635s\n",
      "loss:   2.8649203777313232,   acc:  0.28125\n",
      "loss:   3.0461957454681396,   acc:  0.34375\n",
      "Done with epoch 282 in 2.4044268131256104s\n",
      "loss:   2.5101709365844727,   acc:  0.40625\n",
      "Done with epoch 283 in 2.3771355152130127s\n",
      "loss:   2.667184829711914,   acc:  0.3125\n",
      "Done with epoch 284 in 2.3890037536621094s\n",
      "loss:   3.329435110092163,   acc:  0.25\n",
      "loss:   3.4634335041046143,   acc:  0.3125\n",
      "Done with epoch 285 in 2.4303572177886963s\n",
      "loss:   3.1240313053131104,   acc:  0.28125\n",
      "Done with epoch 286 in 2.3720650672912598s\n",
      "loss:   3.228062629699707,   acc:  0.28125\n",
      "loss:   2.693227767944336,   acc:  0.28125\n",
      "Done with epoch 287 in 2.45539927482605s\n",
      "loss:   3.5957558155059814,   acc:  0.28125\n",
      "Done with epoch 288 in 2.351125955581665s\n",
      "loss:   2.8225338459014893,   acc:  0.40625\n",
      "loss:   3.1359810829162598,   acc:  0.34375\n",
      "Done with epoch 289 in 2.3228163719177246s\n",
      "loss:   3.106355905532837,   acc:  0.3125\n",
      "Done with epoch 290 in 2.295039176940918s\n",
      "loss:   2.1557750701904297,   acc:  0.5\n",
      "Done with epoch 291 in 2.330604314804077s\n",
      "loss:   2.9876890182495117,   acc:  0.34375\n",
      "loss:   3.1922059059143066,   acc:  0.25\n",
      "Done with epoch 292 in 2.403468132019043s\n",
      "loss:   3.3620712757110596,   acc:  0.375\n",
      "Done with epoch 293 in 2.353437900543213s\n",
      "loss:   3.4852347373962402,   acc:  0.3125\n",
      "loss:   2.975850820541382,   acc:  0.28125\n",
      "Done with epoch 294 in 2.4403457641601562s\n",
      "loss:   2.816796064376831,   acc:  0.3125\n",
      "Done with epoch 295 in 2.382232427597046s\n",
      "loss:   2.7491304874420166,   acc:  0.40625\n",
      "Done with epoch 296 in 2.375201463699341s\n",
      "loss:   2.913989305496216,   acc:  0.28125\n",
      "loss:   2.295335531234741,   acc:  0.53125\n",
      "Done with epoch 297 in 2.3869829177856445s\n",
      "loss:   2.951122999191284,   acc:  0.375\n",
      "Saved model at /home/acauligi/cs_234/project/mlopt-micp/mlopt_free_flyer_20200629_1521.pt\n",
      "Done with epoch 298 in 2.3548145294189453s\n",
      "loss:   3.31209659576416,   acc:  0.1875\n",
      "loss:   2.6380972862243652,   acc:  0.3125\n",
      "Done with epoch 299 in 2.3896524906158447s\n",
      "loss:   3.09973406791687,   acc:  0.15625\n",
      "Done with epoch 300 in 2.299938440322876s\n",
      "loss:   2.7189834117889404,   acc:  0.4375\n",
      "Done with epoch 301 in 2.3596742153167725s\n",
      "loss:   2.9097375869750977,   acc:  0.3125\n",
      "loss:   3.4720888137817383,   acc:  0.28125\n",
      "Done with epoch 302 in 2.3955211639404297s\n",
      "loss:   2.991086483001709,   acc:  0.375\n",
      "Done with epoch 303 in 2.3892056941986084s\n",
      "loss:   2.5982253551483154,   acc:  0.34375\n",
      "loss:   2.9105818271636963,   acc:  0.34375\n",
      "Done with epoch 304 in 2.4325685501098633s\n",
      "loss:   2.781764268875122,   acc:  0.3125\n",
      "Done with epoch 305 in 2.2929351329803467s\n",
      "loss:   3.0544581413269043,   acc:  0.34375\n",
      "Done with epoch 306 in 2.270390510559082s\n",
      "loss:   3.4162986278533936,   acc:  0.28125\n",
      "loss:   3.1337080001831055,   acc:  0.1875\n",
      "Done with epoch 307 in 2.3536367416381836s\n",
      "loss:   2.837179183959961,   acc:  0.25\n",
      "Done with epoch 308 in 2.3436617851257324s\n",
      "loss:   3.098775625228882,   acc:  0.25\n",
      "loss:   3.27777099609375,   acc:  0.25\n",
      "Done with epoch 309 in 2.3958380222320557s\n",
      "loss:   2.982217788696289,   acc:  0.375\n",
      "Done with epoch 310 in 2.387735366821289s\n",
      "loss:   3.3928401470184326,   acc:  0.1875\n",
      "Done with epoch 311 in 2.2458057403564453s\n",
      "loss:   2.731553792953491,   acc:  0.3125\n",
      "loss:   2.801100254058838,   acc:  0.4375\n",
      "Done with epoch 312 in 2.3352653980255127s\n",
      "loss:   2.9653515815734863,   acc:  0.25\n",
      "Done with epoch 313 in 2.2716922760009766s\n",
      "loss:   2.7163381576538086,   acc:  0.34375\n",
      "loss:   2.962686061859131,   acc:  0.375\n",
      "Done with epoch 314 in 2.3365087509155273s\n",
      "loss:   2.655552387237549,   acc:  0.375\n",
      "Done with epoch 315 in 2.2765767574310303s\n",
      "loss:   3.340834379196167,   acc:  0.28125\n",
      "loss:   2.642618179321289,   acc:  0.375\n",
      "Done with epoch 316 in 2.4308574199676514s\n",
      "loss:   2.379446506500244,   acc:  0.375\n",
      "Done with epoch 317 in 2.2540738582611084s\n",
      "loss:   2.527820110321045,   acc:  0.40625\n",
      "Done with epoch 318 in 2.255406379699707s\n",
      "loss:   2.733299493789673,   acc:  0.4375\n",
      "loss:   3.110914945602417,   acc:  0.3125\n",
      "Saved model at /home/acauligi/cs_234/project/mlopt-micp/mlopt_free_flyer_20200629_1521.pt\n",
      "Done with epoch 319 in 2.315582752227783s\n",
      "loss:   3.172858953475952,   acc:  0.28125\n",
      "Done with epoch 320 in 2.35646915435791s\n",
      "loss:   3.2800776958465576,   acc:  0.375\n",
      "loss:   3.093897581100464,   acc:  0.3125\n",
      "Done with epoch 321 in 2.4019527435302734s\n",
      "loss:   2.942063331604004,   acc:  0.21875\n",
      "Done with epoch 322 in 2.350588083267212s\n",
      "loss:   3.089541435241699,   acc:  0.34375\n",
      "Done with epoch 323 in 2.3365867137908936s\n",
      "loss:   3.423870325088501,   acc:  0.21875\n",
      "loss:   2.344010829925537,   acc:  0.46875\n",
      "Done with epoch 324 in 2.355649471282959s\n",
      "loss:   2.847569227218628,   acc:  0.28125\n",
      "Done with epoch 325 in 2.313058614730835s\n",
      "loss:   3.035885810852051,   acc:  0.28125\n",
      "loss:   3.04008150100708,   acc:  0.375\n",
      "Done with epoch 326 in 2.361788511276245s\n",
      "loss:   3.2286808490753174,   acc:  0.21875\n",
      "Done with epoch 327 in 2.3590707778930664s\n",
      "loss:   3.4629995822906494,   acc:  0.3125\n",
      "Done with epoch 328 in 2.3402841091156006s\n",
      "loss:   2.448047161102295,   acc:  0.4375\n",
      "loss:   2.886591911315918,   acc:  0.3125\n",
      "Done with epoch 329 in 2.424267053604126s\n",
      "loss:   3.196826934814453,   acc:  0.3125\n",
      "Done with epoch 330 in 2.343207836151123s\n",
      "loss:   3.31998872756958,   acc:  0.28125\n",
      "loss:   2.831960916519165,   acc:  0.375\n",
      "Done with epoch 331 in 2.41605806350708s\n",
      "loss:   2.729761838912964,   acc:  0.40625\n",
      "Done with epoch 332 in 2.2959375381469727s\n",
      "loss:   3.3295655250549316,   acc:  0.21875\n",
      "Done with epoch 333 in 2.358659505844116s\n",
      "loss:   2.157545566558838,   acc:  0.5\n",
      "loss:   3.3054332733154297,   acc:  0.21875\n",
      "Done with epoch 334 in 2.4006195068359375s\n",
      "loss:   2.8769233226776123,   acc:  0.25\n",
      "Done with epoch 335 in 2.363901376724243s\n",
      "loss:   3.2232022285461426,   acc:  0.25\n",
      "loss:   2.8583362102508545,   acc:  0.28125\n",
      "Done with epoch 336 in 2.401311159133911s\n",
      "loss:   3.5299577713012695,   acc:  0.3125\n",
      "Done with epoch 337 in 2.358665943145752s\n",
      "loss:   3.3901426792144775,   acc:  0.21875\n",
      "Done with epoch 338 in 2.338289976119995s\n",
      "loss:   2.9429526329040527,   acc:  0.3125\n",
      "loss:   3.0669031143188477,   acc:  0.3125\n",
      "Done with epoch 339 in 2.3268160820007324s\n",
      "loss:   3.270688772201538,   acc:  0.34375\n",
      "Done with epoch 340 in 2.3213582038879395s\n",
      "loss:   2.4777936935424805,   acc:  0.5\n",
      "Saved model at /home/acauligi/cs_234/project/mlopt-micp/mlopt_free_flyer_20200629_1521.pt\n",
      "loss:   2.8051555156707764,   acc:  0.4375\n",
      "Done with epoch 341 in 2.387756109237671s\n",
      "loss:   3.102830648422241,   acc:  0.28125\n",
      "Done with epoch 342 in 2.3458099365234375s\n",
      "loss:   3.8204727172851562,   acc:  0.21875\n",
      "loss:   3.446683406829834,   acc:  0.15625\n",
      "Done with epoch 343 in 2.4051849842071533s\n",
      "loss:   3.6086812019348145,   acc:  0.1875\n",
      "Done with epoch 344 in 2.32985258102417s\n",
      "loss:   2.9377646446228027,   acc:  0.1875\n",
      "Done with epoch 345 in 2.340810537338257s\n",
      "loss:   2.9750287532806396,   acc:  0.375\n",
      "loss:   3.0034713745117188,   acc:  0.28125\n",
      "Done with epoch 346 in 2.4406867027282715s\n",
      "loss:   3.266409158706665,   acc:  0.25\n",
      "Done with epoch 347 in 2.382561683654785s\n",
      "loss:   3.116657257080078,   acc:  0.34375\n",
      "loss:   3.0931525230407715,   acc:  0.34375\n",
      "Done with epoch 348 in 2.433419704437256s\n",
      "loss:   3.187910795211792,   acc:  0.3125\n",
      "Done with epoch 349 in 2.32978892326355s\n",
      "loss:   3.0167081356048584,   acc:  0.34375\n",
      "Done with epoch 350 in 2.329528331756592s\n",
      "loss:   2.4247143268585205,   acc:  0.375\n",
      "loss:   3.198009967803955,   acc:  0.28125\n",
      "Done with epoch 351 in 2.4258172512054443s\n",
      "loss:   3.2170674800872803,   acc:  0.25\n",
      "Done with epoch 352 in 2.394723415374756s\n",
      "loss:   3.434875249862671,   acc:  0.28125\n",
      "loss:   3.2779805660247803,   acc:  0.1875\n",
      "Done with epoch 353 in 2.4290566444396973s\n",
      "loss:   3.527461290359497,   acc:  0.28125\n",
      "Done with epoch 354 in 2.4037463665008545s\n",
      "loss:   3.5348517894744873,   acc:  0.1875\n",
      "Done with epoch 355 in 2.393665313720703s\n",
      "loss:   3.6414661407470703,   acc:  0.21875\n",
      "loss:   2.8122923374176025,   acc:  0.21875\n",
      "Done with epoch 356 in 2.4192044734954834s\n",
      "loss:   2.4987545013427734,   acc:  0.46875\n",
      "Done with epoch 357 in 2.343008041381836s\n",
      "loss:   3.3673884868621826,   acc:  0.21875\n",
      "loss:   2.370248794555664,   acc:  0.5\n",
      "Done with epoch 358 in 2.398721694946289s\n",
      "loss:   2.6061015129089355,   acc:  0.4375\n",
      "Done with epoch 359 in 2.3565351963043213s\n",
      "loss:   3.3856256008148193,   acc:  0.125\n",
      "Done with epoch 360 in 2.298220157623291s\n",
      "loss:   3.55916690826416,   acc:  0.21875\n",
      "loss:   2.224283218383789,   acc:  0.5\n",
      "Done with epoch 361 in 2.4347660541534424s\n",
      "loss:   3.142956018447876,   acc:  0.28125\n",
      "Saved model at /home/acauligi/cs_234/project/mlopt-micp/mlopt_free_flyer_20200629_1521.pt\n",
      "Done with epoch 362 in 2.33235239982605s\n",
      "loss:   2.7302491664886475,   acc:  0.28125\n",
      "loss:   2.457751989364624,   acc:  0.46875\n",
      "Done with epoch 363 in 2.3676490783691406s\n",
      "loss:   2.5532307624816895,   acc:  0.375\n",
      "Done with epoch 364 in 2.335561513900757s\n",
      "loss:   3.1022253036499023,   acc:  0.25\n",
      "Done with epoch 365 in 2.363373279571533s\n",
      "loss:   3.095531940460205,   acc:  0.3125\n",
      "loss:   3.15509033203125,   acc:  0.375\n",
      "Done with epoch 366 in 2.424485445022583s\n",
      "loss:   2.7348473072052,   acc:  0.375\n",
      "Done with epoch 367 in 2.35490345954895s\n",
      "loss:   2.5694777965545654,   acc:  0.28125\n",
      "loss:   4.174654006958008,   acc:  0.0625\n",
      "Done with epoch 368 in 2.4195480346679688s\n",
      "loss:   3.8248517513275146,   acc:  0.0625\n",
      "Done with epoch 369 in 2.364194869995117s\n",
      "loss:   3.1773016452789307,   acc:  0.28125\n",
      "Done with epoch 370 in 2.3632209300994873s\n",
      "loss:   3.1696319580078125,   acc:  0.28125\n",
      "loss:   3.2723371982574463,   acc:  0.21875\n",
      "Done with epoch 371 in 2.351160764694214s\n",
      "loss:   3.1484012603759766,   acc:  0.28125\n",
      "Done with epoch 372 in 2.352309465408325s\n",
      "loss:   2.767197847366333,   acc:  0.34375\n",
      "loss:   2.4612317085266113,   acc:  0.40625\n",
      "Done with epoch 373 in 2.4171969890594482s\n",
      "loss:   3.4948043823242188,   acc:  0.125\n",
      "Done with epoch 374 in 2.348008871078491s\n",
      "loss:   3.030470848083496,   acc:  0.28125\n",
      "loss:   2.9865875244140625,   acc:  0.34375\n",
      "Done with epoch 375 in 2.414292573928833s\n",
      "loss:   3.256201982498169,   acc:  0.3125\n",
      "Done with epoch 376 in 2.316941738128662s\n",
      "loss:   2.856405019760132,   acc:  0.40625\n",
      "Done with epoch 377 in 2.3496785163879395s\n",
      "loss:   3.0921530723571777,   acc:  0.28125\n",
      "loss:   3.2134287357330322,   acc:  0.25\n",
      "Done with epoch 378 in 2.380892038345337s\n",
      "loss:   3.1620728969573975,   acc:  0.3125\n",
      "Done with epoch 379 in 2.348299264907837s\n",
      "loss:   3.3973865509033203,   acc:  0.25\n",
      "loss:   2.640638828277588,   acc:  0.34375\n",
      "Done with epoch 380 in 2.418409824371338s\n",
      "loss:   2.9337964057922363,   acc:  0.40625\n",
      "Done with epoch 381 in 2.3349039554595947s\n",
      "loss:   3.1409876346588135,   acc:  0.3125\n",
      "Done with epoch 382 in 2.332075595855713s\n",
      "loss:   3.1300225257873535,   acc:  0.3125\n",
      "loss:   2.899824857711792,   acc:  0.3125\n",
      "Saved model at /home/acauligi/cs_234/project/mlopt-micp/mlopt_free_flyer_20200629_1521.pt\n",
      "Done with epoch 383 in 2.399346351623535s\n",
      "loss:   3.372905731201172,   acc:  0.21875\n",
      "Done with epoch 384 in 2.3943183422088623s\n",
      "loss:   2.835620880126953,   acc:  0.3125\n",
      "loss:   3.2881381511688232,   acc:  0.25\n",
      "Done with epoch 385 in 2.4124491214752197s\n",
      "loss:   3.789949417114258,   acc:  0.15625\n",
      "Done with epoch 386 in 2.3260679244995117s\n",
      "loss:   3.574171543121338,   acc:  0.21875\n",
      "Done with epoch 387 in 2.3734591007232666s\n",
      "loss:   3.0415940284729004,   acc:  0.3125\n",
      "loss:   2.554644823074341,   acc:  0.34375\n",
      "Done with epoch 388 in 2.4321117401123047s\n",
      "loss:   3.0809924602508545,   acc:  0.28125\n",
      "Done with epoch 389 in 2.3184139728546143s\n",
      "loss:   3.1495392322540283,   acc:  0.375\n",
      "loss:   3.0527780055999756,   acc:  0.1875\n",
      "Done with epoch 390 in 2.406027317047119s\n",
      "loss:   3.001901865005493,   acc:  0.40625\n",
      "Done with epoch 391 in 2.391326665878296s\n",
      "loss:   3.2339675426483154,   acc:  0.3125\n",
      "Done with epoch 392 in 2.388206958770752s\n",
      "loss:   2.7656896114349365,   acc:  0.25\n",
      "loss:   3.4554834365844727,   acc:  0.28125\n",
      "Done with epoch 393 in 2.430736541748047s\n",
      "loss:   3.2220911979675293,   acc:  0.3125\n",
      "Done with epoch 394 in 2.388218641281128s\n",
      "loss:   3.0079169273376465,   acc:  0.3125\n",
      "loss:   2.997805595397949,   acc:  0.25\n",
      "Done with epoch 395 in 2.4224486351013184s\n",
      "loss:   2.9518954753875732,   acc:  0.25\n",
      "Done with epoch 396 in 2.365508556365967s\n",
      "loss:   3.666006326675415,   acc:  0.28125\n",
      "Done with epoch 397 in 2.394944429397583s\n",
      "loss:   3.0609183311462402,   acc:  0.34375\n",
      "loss:   2.8712990283966064,   acc:  0.40625\n",
      "Done with epoch 398 in 2.38871693611145s\n",
      "loss:   3.190882444381714,   acc:  0.25\n",
      "Done with epoch 399 in 2.325363874435425s\n",
      "loss:   2.7332894802093506,   acc:  0.34375\n",
      "loss:   2.6753194332122803,   acc:  0.4375\n",
      "Done with epoch 400 in 2.3956212997436523s\n",
      "loss:   3.2517950534820557,   acc:  0.1875\n",
      "Done with epoch 401 in 2.351576089859009s\n",
      "loss:   3.3163254261016846,   acc:  0.21875\n",
      "loss:   3.4500057697296143,   acc:  0.21875\n",
      "Done with epoch 402 in 2.3912127017974854s\n",
      "loss:   2.7766478061676025,   acc:  0.40625\n",
      "Done with epoch 403 in 2.3893511295318604s\n",
      "loss:   2.7217211723327637,   acc:  0.46875\n",
      "Done with epoch 404 in 2.38670015335083s\n",
      "loss:   3.087930917739868,   acc:  0.3125\n",
      "Saved model at /home/acauligi/cs_234/project/mlopt-micp/mlopt_free_flyer_20200629_1521.pt\n",
      "loss:   2.6918177604675293,   acc:  0.4375\n",
      "Done with epoch 405 in 2.4638044834136963s\n",
      "loss:   2.364367961883545,   acc:  0.34375\n",
      "Done with epoch 406 in 2.4163525104522705s\n",
      "loss:   2.970822334289551,   acc:  0.375\n",
      "loss:   3.06154727935791,   acc:  0.28125\n",
      "Done with epoch 407 in 2.4091267585754395s\n",
      "loss:   2.6832895278930664,   acc:  0.4375\n",
      "Done with epoch 408 in 2.3653907775878906s\n",
      "loss:   3.9790096282958984,   acc:  0.125\n",
      "Done with epoch 409 in 2.338104486465454s\n",
      "loss:   3.021090269088745,   acc:  0.34375\n",
      "loss:   2.8359689712524414,   acc:  0.375\n",
      "Done with epoch 410 in 2.4426522254943848s\n",
      "loss:   3.3004369735717773,   acc:  0.3125\n",
      "Done with epoch 411 in 2.3984036445617676s\n",
      "loss:   2.9981420040130615,   acc:  0.375\n",
      "loss:   2.866086483001709,   acc:  0.34375\n",
      "Done with epoch 412 in 2.462834119796753s\n",
      "loss:   1.9268078804016113,   acc:  0.5625\n",
      "Done with epoch 413 in 2.350369691848755s\n",
      "loss:   3.0394294261932373,   acc:  0.21875\n",
      "Done with epoch 414 in 2.2713871002197266s\n",
      "loss:   2.9723448753356934,   acc:  0.25\n",
      "loss:   2.545400381088257,   acc:  0.4375\n",
      "Done with epoch 415 in 2.338294267654419s\n",
      "loss:   3.2127864360809326,   acc:  0.3125\n",
      "Done with epoch 416 in 2.3719866275787354s\n",
      "loss:   2.6864840984344482,   acc:  0.40625\n",
      "loss:   3.1020097732543945,   acc:  0.3125\n",
      "Done with epoch 417 in 2.41538667678833s\n",
      "loss:   3.0174930095672607,   acc:  0.3125\n",
      "Done with epoch 418 in 2.3299996852874756s\n",
      "loss:   3.487138271331787,   acc:  0.15625\n",
      "Done with epoch 419 in 2.264054298400879s\n",
      "loss:   3.1645476818084717,   acc:  0.28125\n",
      "loss:   2.3799095153808594,   acc:  0.40625\n",
      "Done with epoch 420 in 2.3424456119537354s\n",
      "loss:   3.387377977371216,   acc:  0.28125\n",
      "Done with epoch 421 in 2.3103272914886475s\n",
      "loss:   2.9725887775421143,   acc:  0.3125\n",
      "loss:   2.877383232116699,   acc:  0.46875\n",
      "Done with epoch 422 in 2.383457660675049s\n",
      "loss:   3.0252530574798584,   acc:  0.3125\n",
      "Done with epoch 423 in 2.362769365310669s\n",
      "loss:   3.638843059539795,   acc:  0.15625\n",
      "Done with epoch 424 in 2.3736352920532227s\n",
      "loss:   2.8432188034057617,   acc:  0.21875\n",
      "loss:   3.091200590133667,   acc:  0.3125\n",
      "Done with epoch 425 in 2.3903543949127197s\n",
      "loss:   3.249688148498535,   acc:  0.21875\n",
      "Saved model at /home/acauligi/cs_234/project/mlopt-micp/mlopt_free_flyer_20200629_1521.pt\n",
      "Done with epoch 426 in 2.310080051422119s\n",
      "loss:   2.572666645050049,   acc:  0.375\n",
      "loss:   2.4018757343292236,   acc:  0.4375\n",
      "Done with epoch 427 in 2.364912748336792s\n",
      "loss:   2.4937877655029297,   acc:  0.40625\n",
      "Done with epoch 428 in 2.316145420074463s\n",
      "loss:   2.5514259338378906,   acc:  0.34375\n",
      "loss:   3.524988889694214,   acc:  0.25\n",
      "Done with epoch 429 in 2.389777660369873s\n",
      "loss:   2.7501277923583984,   acc:  0.375\n",
      "Done with epoch 430 in 2.342470169067383s\n",
      "loss:   3.2112128734588623,   acc:  0.1875\n",
      "Done with epoch 431 in 2.388305187225342s\n",
      "loss:   2.9114761352539062,   acc:  0.375\n",
      "loss:   3.5424787998199463,   acc:  0.21875\n",
      "Done with epoch 432 in 2.4211392402648926s\n",
      "loss:   3.3820600509643555,   acc:  0.1875\n",
      "Done with epoch 433 in 2.335718870162964s\n",
      "loss:   3.413780927658081,   acc:  0.09375\n",
      "loss:   2.7615156173706055,   acc:  0.25\n",
      "Done with epoch 434 in 2.3456130027770996s\n",
      "loss:   3.0063858032226562,   acc:  0.28125\n",
      "Done with epoch 435 in 2.281449317932129s\n",
      "loss:   3.0713791847229004,   acc:  0.34375\n",
      "Done with epoch 436 in 2.2807161808013916s\n",
      "loss:   3.653719663619995,   acc:  0.28125\n",
      "loss:   2.9917383193969727,   acc:  0.34375\n",
      "Done with epoch 437 in 2.357820749282837s\n",
      "loss:   3.040954113006592,   acc:  0.3125\n",
      "Done with epoch 438 in 2.3505823612213135s\n",
      "loss:   3.063718318939209,   acc:  0.40625\n",
      "loss:   2.739523410797119,   acc:  0.28125\n",
      "Done with epoch 439 in 2.381687879562378s\n",
      "loss:   2.808336019515991,   acc:  0.28125\n",
      "Done with epoch 440 in 2.3408985137939453s\n",
      "loss:   3.0813965797424316,   acc:  0.375\n",
      "Done with epoch 441 in 2.3751730918884277s\n",
      "loss:   3.2685415744781494,   acc:  0.125\n",
      "loss:   3.012326240539551,   acc:  0.34375\n",
      "Done with epoch 442 in 2.3770384788513184s\n",
      "loss:   3.3580899238586426,   acc:  0.1875\n",
      "Done with epoch 443 in 2.387489080429077s\n",
      "loss:   2.8858790397644043,   acc:  0.34375\n",
      "loss:   3.2967875003814697,   acc:  0.15625\n",
      "Done with epoch 444 in 2.3970274925231934s\n",
      "loss:   3.688922882080078,   acc:  0.28125\n",
      "Done with epoch 445 in 2.3417935371398926s\n",
      "loss:   3.7836923599243164,   acc:  0.21875\n",
      "Done with epoch 446 in 2.347243547439575s\n",
      "loss:   2.4489896297454834,   acc:  0.3125\n",
      "loss:   3.3215198516845703,   acc:  0.375\n",
      "Saved model at /home/acauligi/cs_234/project/mlopt-micp/mlopt_free_flyer_20200629_1521.pt\n",
      "Done with epoch 447 in 2.403831958770752s\n",
      "loss:   2.9303886890411377,   acc:  0.3125\n",
      "Done with epoch 448 in 2.3453032970428467s\n",
      "loss:   2.8157105445861816,   acc:  0.21875\n",
      "loss:   3.011666774749756,   acc:  0.25\n",
      "Done with epoch 449 in 2.40063214302063s\n",
      "loss:   3.1028242111206055,   acc:  0.25\n",
      "Done with epoch 450 in 2.342902183532715s\n",
      "loss:   2.6700680255889893,   acc:  0.40625\n",
      "Done with epoch 451 in 2.402583122253418s\n",
      "loss:   3.224036693572998,   acc:  0.21875\n",
      "loss:   3.292811393737793,   acc:  0.28125\n",
      "Done with epoch 452 in 2.3606669902801514s\n",
      "loss:   2.9417073726654053,   acc:  0.3125\n",
      "Done with epoch 453 in 2.278644323348999s\n",
      "loss:   3.0131731033325195,   acc:  0.28125\n",
      "loss:   2.80731201171875,   acc:  0.375\n",
      "Done with epoch 454 in 2.3697097301483154s\n",
      "loss:   3.3661885261535645,   acc:  0.25\n",
      "Done with epoch 455 in 2.3557348251342773s\n",
      "loss:   2.9962785243988037,   acc:  0.34375\n",
      "Done with epoch 456 in 2.400120973587036s\n",
      "loss:   3.2047603130340576,   acc:  0.3125\n",
      "loss:   2.8873753547668457,   acc:  0.4375\n",
      "Done with epoch 457 in 2.4118564128875732s\n",
      "loss:   2.9550201892852783,   acc:  0.375\n",
      "Done with epoch 458 in 2.329920530319214s\n",
      "loss:   3.0288448333740234,   acc:  0.34375\n",
      "loss:   2.412017822265625,   acc:  0.375\n",
      "Done with epoch 459 in 2.427551746368408s\n",
      "loss:   2.977154493331909,   acc:  0.40625\n",
      "Done with epoch 460 in 2.3869733810424805s\n",
      "loss:   2.8997764587402344,   acc:  0.34375\n",
      "loss:   3.2045507431030273,   acc:  0.25\n",
      "Done with epoch 461 in 2.355097770690918s\n",
      "loss:   3.282329797744751,   acc:  0.21875\n",
      "Done with epoch 462 in 2.3445656299591064s\n",
      "loss:   2.451612710952759,   acc:  0.4375\n",
      "Done with epoch 463 in 2.3337550163269043s\n",
      "loss:   3.2526185512542725,   acc:  0.28125\n",
      "loss:   2.9306342601776123,   acc:  0.25\n",
      "Done with epoch 464 in 2.433335304260254s\n",
      "loss:   2.8153860569000244,   acc:  0.3125\n",
      "Done with epoch 465 in 2.3107335567474365s\n",
      "loss:   2.8099355697631836,   acc:  0.21875\n",
      "loss:   3.3434009552001953,   acc:  0.1875\n",
      "Done with epoch 466 in 2.392488718032837s\n",
      "loss:   2.699394941329956,   acc:  0.1875\n",
      "Done with epoch 467 in 2.335827112197876s\n",
      "loss:   3.1288204193115234,   acc:  0.28125\n",
      "Done with epoch 468 in 2.2928664684295654s\n",
      "loss:   3.261495351791382,   acc:  0.375\n",
      "Saved model at /home/acauligi/cs_234/project/mlopt-micp/mlopt_free_flyer_20200629_1521.pt\n",
      "loss:   2.561310052871704,   acc:  0.375\n",
      "Done with epoch 469 in 2.4267570972442627s\n",
      "loss:   3.13177227973938,   acc:  0.3125\n",
      "Done with epoch 470 in 2.3281962871551514s\n",
      "loss:   3.4105336666107178,   acc:  0.21875\n",
      "loss:   2.788332223892212,   acc:  0.25\n",
      "Done with epoch 471 in 2.3883275985717773s\n",
      "loss:   3.0828168392181396,   acc:  0.34375\n",
      "Done with epoch 472 in 2.3239786624908447s\n",
      "loss:   2.449169635772705,   acc:  0.40625\n",
      "Done with epoch 473 in 2.293937921524048s\n",
      "loss:   2.795166492462158,   acc:  0.375\n",
      "loss:   3.5384624004364014,   acc:  0.21875\n",
      "Done with epoch 474 in 2.40313720703125s\n",
      "loss:   3.1258506774902344,   acc:  0.25\n",
      "Done with epoch 475 in 2.334416389465332s\n",
      "loss:   3.5798280239105225,   acc:  0.1875\n",
      "loss:   3.2130067348480225,   acc:  0.21875\n",
      "Done with epoch 476 in 2.3837647438049316s\n",
      "loss:   2.8407766819000244,   acc:  0.34375\n",
      "Done with epoch 477 in 2.3447306156158447s\n",
      "loss:   3.030954360961914,   acc:  0.25\n",
      "Done with epoch 478 in 2.3778603076934814s\n",
      "loss:   3.2924857139587402,   acc:  0.21875\n",
      "loss:   2.8681063652038574,   acc:  0.3125\n",
      "Done with epoch 479 in 2.4402599334716797s\n",
      "loss:   2.448245048522949,   acc:  0.34375\n",
      "Done with epoch 480 in 2.3177530765533447s\n",
      "loss:   3.1078908443450928,   acc:  0.34375\n",
      "loss:   2.6233434677124023,   acc:  0.375\n",
      "Done with epoch 481 in 2.347853422164917s\n",
      "loss:   2.798823118209839,   acc:  0.34375\n",
      "Done with epoch 482 in 2.348799705505371s\n",
      "loss:   2.7864701747894287,   acc:  0.40625\n",
      "Done with epoch 483 in 2.355712890625s\n",
      "loss:   2.6371374130249023,   acc:  0.28125\n",
      "loss:   2.8362152576446533,   acc:  0.375\n",
      "Done with epoch 484 in 2.409522294998169s\n",
      "loss:   2.7343931198120117,   acc:  0.3125\n",
      "Done with epoch 485 in 2.3760342597961426s\n",
      "loss:   3.305549383163452,   acc:  0.15625\n",
      "loss:   3.634340524673462,   acc:  0.125\n",
      "Done with epoch 486 in 2.4176840782165527s\n",
      "loss:   3.272883653640747,   acc:  0.21875\n",
      "Done with epoch 487 in 2.371460437774658s\n",
      "loss:   3.153740406036377,   acc:  0.28125\n",
      "loss:   2.9450478553771973,   acc:  0.28125\n",
      "Done with epoch 488 in 2.421304941177368s\n",
      "loss:   3.0765938758850098,   acc:  0.28125\n",
      "Done with epoch 489 in 2.3747615814208984s\n",
      "loss:   2.4453608989715576,   acc:  0.4375\n",
      "Saved model at /home/acauligi/cs_234/project/mlopt-micp/mlopt_free_flyer_20200629_1521.pt\n",
      "Done with epoch 490 in 2.294839859008789s\n",
      "loss:   3.025763511657715,   acc:  0.21875\n",
      "loss:   2.8661534786224365,   acc:  0.4375\n",
      "Done with epoch 491 in 2.300637722015381s\n",
      "loss:   3.205827236175537,   acc:  0.28125\n",
      "Done with epoch 492 in 2.2542035579681396s\n",
      "loss:   2.53895902633667,   acc:  0.34375\n",
      "loss:   2.76027250289917,   acc:  0.25\n",
      "Done with epoch 493 in 2.418468475341797s\n",
      "loss:   3.1505258083343506,   acc:  0.28125\n",
      "Done with epoch 494 in 2.362872362136841s\n",
      "loss:   2.6107544898986816,   acc:  0.4375\n",
      "Done with epoch 495 in 2.372101306915283s\n",
      "loss:   2.479642868041992,   acc:  0.4375\n",
      "loss:   3.1238231658935547,   acc:  0.34375\n",
      "Done with epoch 496 in 2.444390296936035s\n",
      "loss:   2.701298236846924,   acc:  0.375\n",
      "Done with epoch 497 in 2.326753854751587s\n",
      "loss:   3.53009295463562,   acc:  0.28125\n",
      "loss:   3.048945426940918,   acc:  0.15625\n",
      "Done with epoch 498 in 2.3326525688171387s\n",
      "loss:   2.5144996643066406,   acc:  0.4375\n",
      "Done with epoch 499 in 2.3199307918548584s\n",
      "loss:   2.9444446563720703,   acc:  0.4375\n",
      "Done with epoch 500 in 2.3826005458831787s\n",
      "loss:   2.93880033493042,   acc:  0.46875\n",
      "loss:   3.2153048515319824,   acc:  0.21875\n",
      "Done with epoch 501 in 2.4210145473480225s\n",
      "loss:   3.242398738861084,   acc:  0.21875\n",
      "Done with epoch 502 in 2.3250792026519775s\n",
      "loss:   3.06335711479187,   acc:  0.21875\n",
      "loss:   3.120609760284424,   acc:  0.1875\n",
      "Done with epoch 503 in 2.3884360790252686s\n",
      "loss:   2.844390869140625,   acc:  0.3125\n",
      "Done with epoch 504 in 2.3570973873138428s\n",
      "loss:   3.191366195678711,   acc:  0.34375\n",
      "Done with epoch 505 in 2.3349907398223877s\n",
      "loss:   2.9680910110473633,   acc:  0.25\n",
      "loss:   3.2357676029205322,   acc:  0.375\n",
      "Done with epoch 506 in 2.3461999893188477s\n",
      "loss:   2.6023054122924805,   acc:  0.3125\n",
      "Done with epoch 507 in 2.299179792404175s\n",
      "loss:   2.6510462760925293,   acc:  0.34375\n",
      "loss:   2.792186737060547,   acc:  0.28125\n",
      "Done with epoch 508 in 2.398376703262329s\n",
      "loss:   2.7159292697906494,   acc:  0.3125\n",
      "Done with epoch 509 in 2.3404300212860107s\n",
      "loss:   2.5671403408050537,   acc:  0.5\n",
      "Done with epoch 510 in 2.3850455284118652s\n",
      "loss:   3.0020549297332764,   acc:  0.4375\n",
      "loss:   3.106302261352539,   acc:  0.3125\n",
      "Saved model at /home/acauligi/cs_234/project/mlopt-micp/mlopt_free_flyer_20200629_1521.pt\n",
      "Done with epoch 511 in 2.4319746494293213s\n",
      "loss:   3.4611034393310547,   acc:  0.28125\n",
      "Done with epoch 512 in 2.317976236343384s\n",
      "loss:   3.046947717666626,   acc:  0.375\n",
      "loss:   2.539438486099243,   acc:  0.5\n",
      "Done with epoch 513 in 2.3276848793029785s\n",
      "loss:   2.907299518585205,   acc:  0.40625\n",
      "Done with epoch 514 in 2.296790838241577s\n",
      "loss:   2.5129499435424805,   acc:  0.4375\n",
      "loss:   3.5642764568328857,   acc:  0.21875\n",
      "Done with epoch 515 in 2.4116766452789307s\n",
      "loss:   2.9968862533569336,   acc:  0.3125\n",
      "Done with epoch 516 in 2.3573951721191406s\n",
      "loss:   2.908331871032715,   acc:  0.34375\n",
      "Done with epoch 517 in 2.365999460220337s\n",
      "loss:   2.8571343421936035,   acc:  0.25\n",
      "loss:   2.3784687519073486,   acc:  0.4375\n",
      "Done with epoch 518 in 2.3772807121276855s\n",
      "loss:   2.758310556411743,   acc:  0.40625\n",
      "Done with epoch 519 in 2.32004451751709s\n",
      "loss:   2.7983503341674805,   acc:  0.46875\n",
      "loss:   2.4895060062408447,   acc:  0.375\n",
      "Done with epoch 520 in 2.397509813308716s\n",
      "loss:   3.008289337158203,   acc:  0.34375\n",
      "Done with epoch 521 in 2.3857529163360596s\n",
      "loss:   3.086993932723999,   acc:  0.25\n",
      "Done with epoch 522 in 2.3070480823516846s\n",
      "loss:   3.84127140045166,   acc:  0.28125\n",
      "loss:   3.260122299194336,   acc:  0.25\n",
      "Done with epoch 523 in 2.373100757598877s\n",
      "loss:   3.3573098182678223,   acc:  0.25\n",
      "Done with epoch 524 in 2.3241055011749268s\n",
      "loss:   3.3850631713867188,   acc:  0.34375\n",
      "loss:   2.579908847808838,   acc:  0.46875\n",
      "Done with epoch 525 in 2.44716739654541s\n",
      "loss:   3.2821431159973145,   acc:  0.21875\n",
      "Done with epoch 526 in 2.3698458671569824s\n",
      "loss:   3.21174955368042,   acc:  0.25\n",
      "Done with epoch 527 in 2.369612455368042s\n",
      "loss:   3.03397274017334,   acc:  0.375\n",
      "loss:   2.6668903827667236,   acc:  0.4375\n",
      "Done with epoch 528 in 2.431736469268799s\n",
      "loss:   2.9295809268951416,   acc:  0.34375\n",
      "Done with epoch 529 in 2.3166277408599854s\n",
      "loss:   3.504697322845459,   acc:  0.15625\n",
      "loss:   3.346867561340332,   acc:  0.25\n",
      "Done with epoch 530 in 2.3605315685272217s\n",
      "loss:   2.946295738220215,   acc:  0.34375\n",
      "Done with epoch 531 in 2.335268259048462s\n",
      "loss:   3.0388615131378174,   acc:  0.28125\n",
      "Done with epoch 532 in 2.407672643661499s\n",
      "loss:   2.7427926063537598,   acc:  0.40625\n",
      "Saved model at /home/acauligi/cs_234/project/mlopt-micp/mlopt_free_flyer_20200629_1521.pt\n",
      "loss:   2.6667826175689697,   acc:  0.375\n",
      "Done with epoch 533 in 2.40885591506958s\n",
      "loss:   3.2169017791748047,   acc:  0.3125\n",
      "Done with epoch 534 in 2.30542254447937s\n",
      "loss:   3.036952257156372,   acc:  0.21875\n",
      "loss:   3.613276481628418,   acc:  0.1875\n",
      "Done with epoch 535 in 2.3317525386810303s\n",
      "loss:   3.3061373233795166,   acc:  0.28125\n",
      "Done with epoch 536 in 2.3268725872039795s\n",
      "loss:   2.56514573097229,   acc:  0.46875\n",
      "Done with epoch 537 in 2.3829612731933594s\n",
      "loss:   2.747920513153076,   acc:  0.375\n",
      "loss:   3.06249737739563,   acc:  0.21875\n",
      "Done with epoch 538 in 2.3970370292663574s\n",
      "loss:   3.3923943042755127,   acc:  0.3125\n",
      "Done with epoch 539 in 2.333711624145508s\n",
      "loss:   2.390181064605713,   acc:  0.53125\n",
      "loss:   2.7923295497894287,   acc:  0.375\n",
      "Done with epoch 540 in 2.3837339878082275s\n",
      "loss:   3.054368495941162,   acc:  0.25\n",
      "Done with epoch 541 in 2.354116439819336s\n",
      "loss:   2.8209125995635986,   acc:  0.28125\n",
      "loss:   3.1646461486816406,   acc:  0.34375\n",
      "Done with epoch 542 in 2.4584059715270996s\n",
      "loss:   2.850952625274658,   acc:  0.40625\n",
      "Done with epoch 543 in 2.366813898086548s\n",
      "loss:   3.280362129211426,   acc:  0.1875\n",
      "Done with epoch 544 in 2.399171829223633s\n",
      "loss:   2.3279943466186523,   acc:  0.46875\n",
      "loss:   3.2639055252075195,   acc:  0.28125\n",
      "Done with epoch 545 in 2.415090799331665s\n",
      "loss:   3.963571548461914,   acc:  0.21875\n",
      "Done with epoch 546 in 2.3416202068328857s\n",
      "loss:   2.9196114540100098,   acc:  0.34375\n",
      "loss:   3.0604453086853027,   acc:  0.34375\n",
      "Done with epoch 547 in 2.373962879180908s\n",
      "loss:   2.866377830505371,   acc:  0.3125\n",
      "Done with epoch 548 in 2.3323047161102295s\n",
      "loss:   3.3156514167785645,   acc:  0.21875\n",
      "Done with epoch 549 in 2.388108730316162s\n",
      "loss:   3.626436471939087,   acc:  0.25\n",
      "loss:   3.0284063816070557,   acc:  0.375\n",
      "Done with epoch 550 in 2.3754711151123047s\n",
      "loss:   2.6726369857788086,   acc:  0.3125\n",
      "Done with epoch 551 in 2.351069211959839s\n",
      "loss:   2.3983049392700195,   acc:  0.34375\n",
      "loss:   2.4833662509918213,   acc:  0.46875\n",
      "Done with epoch 552 in 2.4019360542297363s\n",
      "loss:   2.8441691398620605,   acc:  0.3125\n",
      "Done with epoch 553 in 2.3652243614196777s\n",
      "loss:   2.7139272689819336,   acc:  0.375\n",
      "Saved model at /home/acauligi/cs_234/project/mlopt-micp/mlopt_free_flyer_20200629_1521.pt\n",
      "Done with epoch 554 in 2.3305776119232178s\n",
      "loss:   3.107297420501709,   acc:  0.375\n",
      "loss:   3.3997297286987305,   acc:  0.1875\n",
      "Done with epoch 555 in 2.3193068504333496s\n",
      "loss:   2.8711109161376953,   acc:  0.25\n",
      "Done with epoch 556 in 2.2671854496002197s\n",
      "loss:   3.3376498222351074,   acc:  0.28125\n",
      "loss:   2.495262861251831,   acc:  0.4375\n",
      "Done with epoch 557 in 2.3134021759033203s\n",
      "loss:   2.6973814964294434,   acc:  0.375\n",
      "Done with epoch 558 in 2.271038293838501s\n",
      "loss:   2.79063081741333,   acc:  0.3125\n",
      "Done with epoch 559 in 2.2781028747558594s\n",
      "loss:   3.1767685413360596,   acc:  0.3125\n",
      "loss:   2.690539598464966,   acc:  0.3125\n",
      "Done with epoch 560 in 2.361551284790039s\n",
      "loss:   2.8304593563079834,   acc:  0.375\n",
      "Done with epoch 561 in 2.3598806858062744s\n",
      "loss:   2.8992373943328857,   acc:  0.34375\n",
      "loss:   2.7568721771240234,   acc:  0.375\n",
      "Done with epoch 562 in 2.4529852867126465s\n",
      "loss:   2.948246717453003,   acc:  0.28125\n",
      "Done with epoch 563 in 2.389474391937256s\n",
      "loss:   2.7939059734344482,   acc:  0.3125\n",
      "Done with epoch 564 in 2.3809425830841064s\n",
      "loss:   2.769663095474243,   acc:  0.25\n",
      "loss:   2.3040082454681396,   acc:  0.46875\n",
      "Done with epoch 565 in 2.390279531478882s\n",
      "loss:   2.6805107593536377,   acc:  0.3125\n",
      "Done with epoch 566 in 2.3614330291748047s\n",
      "loss:   3.475480079650879,   acc:  0.25\n",
      "loss:   3.5357887744903564,   acc:  0.25\n",
      "Done with epoch 567 in 2.3843657970428467s\n",
      "loss:   2.8507518768310547,   acc:  0.3125\n",
      "Done with epoch 568 in 2.3189074993133545s\n",
      "loss:   2.9617416858673096,   acc:  0.34375\n",
      "Done with epoch 569 in 2.3338494300842285s\n",
      "loss:   2.963275671005249,   acc:  0.375\n",
      "loss:   2.461752414703369,   acc:  0.53125\n",
      "Done with epoch 570 in 2.378371477127075s\n",
      "loss:   3.011509418487549,   acc:  0.28125\n",
      "Done with epoch 571 in 2.36529278755188s\n",
      "loss:   2.779069423675537,   acc:  0.21875\n",
      "loss:   2.967714548110962,   acc:  0.34375\n",
      "Done with epoch 572 in 2.4188616275787354s\n",
      "loss:   3.3667221069335938,   acc:  0.21875\n",
      "Done with epoch 573 in 2.362105369567871s\n",
      "loss:   2.8202900886535645,   acc:  0.40625\n",
      "loss:   2.7377214431762695,   acc:  0.34375\n",
      "Done with epoch 574 in 2.4304583072662354s\n",
      "loss:   2.8120243549346924,   acc:  0.5\n",
      "Saved model at /home/acauligi/cs_234/project/mlopt-micp/mlopt_free_flyer_20200629_1521.pt\n",
      "Done with epoch 575 in 2.344119071960449s\n",
      "loss:   3.0703887939453125,   acc:  0.28125\n",
      "Done with epoch 576 in 2.3835175037384033s\n",
      "loss:   3.213832378387451,   acc:  0.28125\n",
      "loss:   2.8828351497650146,   acc:  0.28125\n",
      "Done with epoch 577 in 2.3921682834625244s\n",
      "loss:   3.049240827560425,   acc:  0.375\n",
      "Done with epoch 578 in 2.313539743423462s\n",
      "loss:   3.127568244934082,   acc:  0.21875\n",
      "loss:   2.6253747940063477,   acc:  0.46875\n",
      "Done with epoch 579 in 2.3475046157836914s\n",
      "loss:   2.5253043174743652,   acc:  0.40625\n",
      "Done with epoch 580 in 2.3809921741485596s\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-37-05f0c99e5608>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mmlopt_ts_obj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtraining_params\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'TRAINING_ITERATIONS'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1000\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mmlopt_ts_obj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmlopt_ts_obj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel_fn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/cs_234/project/mlopt-micp/solvers/mlopt_ff.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self, verbose)\u001b[0m\n\u001b[1;32m    178\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mii\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0midx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindices\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    179\u001b[0m                 \u001b[0;31m# zero the parameter gradients\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 180\u001b[0;31m                 \u001b[0mopt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    181\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    182\u001b[0m                 \u001b[0mff_inputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mVariable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_numpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/cs_234/project/mlopt-micp/mlopt/lib/python3.6/site-packages/torch/optim/optimizer.py\u001b[0m in \u001b[0;36mzero_grad\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    161\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mgroup\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparam_groups\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    162\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mp\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mgroup\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'params'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 163\u001b[0;31m                 \u001b[0;32mif\u001b[0m \u001b[0mp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgrad\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    164\u001b[0m                     \u001b[0mp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgrad\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdetach_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    165\u001b[0m                     \u001b[0mp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgrad\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/cs_234/project/mlopt-micp/mlopt/lib/python3.6/site-packages/torch/tensor.py\u001b[0m in \u001b[0;36mgrad\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    735\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrename\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnames\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    736\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 737\u001b[0;31m     \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    738\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mgrad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    739\u001b[0m         \"\"\"\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "mlopt_ts_obj.training_params['TRAINING_ITERATIONS'] = 1000\n",
    "mlopt_ts_obj.train()\n",
    "print(mlopt_ts_obj.model_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "86.93769079671627\n"
     ]
    }
   ],
   "source": [
    "prob_params = {}\n",
    "idx = np.random.randint(test_data[1].shape[0])\n",
    "\n",
    "p_test = test_data[0]\n",
    "for k in p_test.keys():\n",
    "    prob_params[k] = p_test[k][idx]\n",
    "prob_success, cost, total_time, n_evals = mlopt_ts_obj.forward(prob_params)\n",
    "\n",
    "if prob_success:\n",
    "    print(cost)\n",
    "else:\n",
    "    print('Failed')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.16"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n_succ = 0\n",
    "count = 0\n",
    "for ii in range(25):\n",
    "    prob_params = {}\n",
    "    idx = np.random.randint(test_data[1].shape[0])\n",
    "\n",
    "    p_test = test_data[0]\n",
    "    for k in p_test.keys():\n",
    "        prob_params[k] = p_test[k][idx]\n",
    "    prob_success, cost, total_time, n_evals = mlopt_ts_obj.forward(prob_params)\n",
    "\n",
    "    count += 1\n",
    "    if prob_success:\n",
    "        n_succ += 1\n",
    "\n",
    "float(n_succ) / float(count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "86.93769129480138"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prob_success, true_cost, solve_time, optvals = mlopt_ts_obj.problem.solve_micp(prob_params)\n",
    "\n",
    "true_cost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x0 = train_data[0]['x0'][idx]\n",
    "n_obs = mlopt_ts_obj.problem.n_obs\n",
    "posmin, posmax = mlopt_ts_obj.problem.posmin, mlopt_ts_obj.problem.posmax\n",
    "\n",
    "obstacles = []\n",
    "for ii_obs in range(n_obs):\n",
    "    obs = train_data[0]['obstacles'][idx][:,ii_obs]\n",
    "    obstacles.append(obs)\n",
    "\n",
    "X = optvals[0]\n",
    "\n",
    "plt.axes()\n",
    "for obstacle in obstacles:\n",
    "    rectangle = plt.Rectangle((obstacle[0], obstacle[2]), \\\n",
    "                              obstacle[1]-obstacle[0], obstacle[3]-obstacle[2], \\\n",
    "                             fc='red', ec='blue')\n",
    "    plt.gca().add_patch(rectangle)\n",
    "    plt.axis('scaled')\n",
    "\n",
    "for ii in range(mlopt_ts_obj.problem.N):\n",
    "    circle = plt.Circle((X[0,ii],X[1,ii]), 0.04, fc='blue',ec=\"green\")\n",
    "    plt.gca().add_patch(circle)\n",
    "\n",
    "ax = plt.gca()\n",
    "ax.margins(0)\n",
    "ax.set(xlim=(posmin[0],posmax[0]), ylim=(posmin[1],posmax[1]))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# test Regression solver"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from solvers.regression import Regression\n",
    "\n",
    "system = 'free_flyer'\n",
    "prob_features = ['x0', 'obstacles']\n",
    "reg_obj = Regression(system, prob, prob_features)\n",
    "\n",
    "n_features = 36\n",
    "reg_obj.construct_strategies(n_features, train_data)\n",
    "print(reg_obj.n_strategies)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reg_obj.setup_network()\n",
    "\n",
    "reg_obj.model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reg_obj.training_params['TRAINING_ITERATIONS'] = 10000\n",
    "reg_obj.training_params['CHECKPOINT_AFTER'] = 200000\n",
    "reg_obj.train()\n",
    "print(reg_obj.model_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prob_params = {}\n",
    "idx = np.random.randint(test_data[1].shape[0])\n",
    "\n",
    "p_test = test_data[0]\n",
    "for k in p_test.keys():\n",
    "    prob_params[k] = p_test[k][idx]\n",
    "prob_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prob_success, cost, total_time = reg_obj.forward(prob_params)\n",
    "\n",
    "if prob_success:\n",
    "    print(cost)\n",
    "else:\n",
    "    print('Failed')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_succ = 0\n",
    "for idx in range(100):\n",
    "    prob_params = {}\n",
    "\n",
    "    p_test = test_data[0]\n",
    "    for k in p_test.keys():\n",
    "        prob_params[k] = p_test[k][idx]\n",
    "\n",
    "    prob_success, cost, total_time = reg_obj.forward(prob_params)\n",
    "    if prob_success:\n",
    "        n_succ +=1\n",
    "\n",
    "print(float(n_succ) / 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prob_success, true_cost, solve_time, optvals = reg_obj.problem.solve_micp(prob_params)\n",
    "\n",
    "true_cost"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mlopt",
   "language": "python",
   "name": "mlopt"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
